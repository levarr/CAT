\documentclass[a4paper]{report}

\input{commands.tex}
\usepackage{rotating}
\usepackage{cancel}
\usepackage[framed]{matlab-prettifier}


\title{
    \textbf{Appunti di Controlli Automatici T} \\
       \large Alma Mater Studiorum - Università di Bologna \\
    \large Facoltà di Ingegneria Informatica - 9254
}
\author{\textbf{Fabio Colonna} - fabcolonna@icloud.com, \\
        fabio.colonna3@studio.unibo.it }
\date{AA 2022-23}

\makeindex
\begin{document}

\maketitle
\tableofcontents
\newpage

\part{Introduzione}

\section{Idea sulla disciplina}

I Controlli Automatici (CA da ora in poi) rappresentano la disciplina che ha come obiettivo primario quello di \textbf{sostituire l'intelligenza unama con un sistema automatico - intelligenza artificiale - in modo da permettere ad una macchina manuale di poter operare in autonomia.} Possiamo chiamare questo processo \textbf{automazione}. Faremo largo uso di modelli matematici per definire con precisione i parametri necessari di cui abbiamo bisogno per generare effettivamente questo comportamento. Le applicazioni di queste tecnologie nel mondo reale sono pressoché infinite al giorno oggi: automotive (si pensi alla guida autonoma, ma anche a sistemi più "semplici" quali il controllo di trazione o l'ESP), apparecchi elettrodomestici, ambito militare (droni, autopilot nei veivoli)...
\bb
Il corso sarà diviso in due parti. La prima, cosiddetta di \textbf{analisi}, verterà su come \textbf{modellare un sistema fisico} utilizzando strumenti matematici per capirne il suo comportamento. Questo può essere fatto guardando il \textbf{comportamento dell'uscita al variare dei parametri in ingresso} del sistema suddetto. La seconda parte, chiamata \textbf{sintesi}, fornirà i metodi per la \textbf{progettazione di un sistema di controllo}, i.e. un \textbf{sistema + controllore}, cioè il dispositivo che a tutti gli effetti implementerà l'automazione, comandando il macchinario (il sistema) al posto nostro. Il punto di vista sarà diverso: \textbf{capire di quali ingressi abbiamo bisogno per generare il comportamento che vogliamo, i.e. l'uscita desiderata.}

\section{Terminologia ed elementi costitutivi}

\begin{defin}{Terminologia}{}
	\begin{enumerate}
		\item \textbf{Sistema} \rarr oggetto/fenomeno fisico per il quale si vuole ottenere un \textit{comportamento desiderato}. Esempi sono: impianti industriali, bracci robotici, veicoli/veivoli... Esso è composto da un \textbf{ingresso}, al quale arriva una grandezza che tipicamente \textbf{modifica il comportamento}, e un'\textbf{uscita}, che rappresenta il suddetto comportamento ed è tipicamente monitorata da \textit{sensori.}
		\item  \textbf{Controllore} \rarr unità di calcolo che determina \textbf{l'andamento delle variabili di ingresso}, in modo tale da generare l'uscita desiderata. A livello analitico questa entità è un sistema di equazioni matematiche.
		\item \textbf{Sistema di controllo} \rarr rappresenta la coppia \textbf{sistema + controllore}, ed è quello che il procedimento di sintesi avrà come obiettivo. 
	\end{enumerate}
\end{defin}


\resource{0.3}{sistema}{Schematizzazione di un sistema}
\bb


Un uomo che guida un'automobile è un esempio di sistema di controllo: l'auto è il sistema, il cervello umano è il controllore. L'uscita del sistema, i.e. la sua velocità o direzione, è monitorata da sensori naturali quali la vista, l'udito, ma anche da artificiali (ad es. il tachimetro). Sulla base di tutti questi dati, il cervello manda in ingresso all'auto un nuovo set di ingressi (angolo di sterzatura, pressione sul pedale acceleratore o freno) in modo da generare il comportamento che vuole.
\newpage
A partire da questo esempio, è possibile introdurre le due principali

\begin{defin}{Tipologie di controllo}{a}
\begin{enumerate}
	\item \textbf{in anello aperto (feedforward)} \rarr il controllore comanda il sistema mandandogli \textbf{ingressi valutati guardando solo il segnale di riferimento};
	\item \textbf{in anello chiuso (feedback)} \rarr oltre a guardare il segnale di riferimento, il controllore \textbf{utilizza anche i dati che istante per istante riceve per mezzo dei sensori.} Questo approccio è senz'altro quello predominante nel mondo dei CA.
\end{enumerate}
\end{defin}

\resource{0.80}{feedback}{Esempio di funzionamento feedback. Notare il segnale che rientra nel controllore (dati dei sensori)}

\section{Progetto di un sistema di controllo}

L'approccio che porta al progetto final e è più o meno il seguente:
\begin{itemize}
	\item \textbf{Definizione delle specifiche} \rarr comportamento desiderato del sistema, costo, indice di performance... Sono tutte informazioni tipicamente vincolate, ossia fornite dal datore di progetto e non modificabili dall'ingegnere;
	\item \textbf{Modellazione del sistema} \rarr eseguito tipicamente con l'aiuto di figure specialistiche del settore nel quale il macchinario poi sarà destinato a lavorare. Ha come obiettivo quello di ricercare modelli aventi un giusto compromesso tra complessità/semplicità nella sintesi, definire gli ingressi e le uscite, procedere con la codifica ed eventualmente validarla mediante simulazioni. Molto spesso si parla di \textit{modello di controllo}, tipicamente di complessità relativamente bassa, e \textit{modello di test}, estremamente più complesso in quanto creato al computer e reso quanto più verosimile possibile;
	\item \textbf{Analisi del sistema} \rarr Eseguito per studiare le \textit{proprietà strutturali} del modello, nonché capirne le sue capacità in modo da trovargli applicazioni opportune;
	\item \textbf{Sintesi della legge di controllo} \rarr A seguito di considerazioni fatte sulla \textit{scelta degli elementi tecnologici} da utilizzare per la realizzazione (device di elaborazione, elettronica di acquisizione/attenuazione, sensori/attuatori...), nonché una fase di sperimentazione eseguibile mediante numerosi approcci (ad es. HW in the loop, in base all quale al prototipo virtuale si inviano controlli provenienti da \textit{schede di controllo reali}), si genera il sistema di controllo finale automatizzato secondo le specifiche.
\end{itemize}

\part{Analisi nel dominio dei tempi}
\chapter{Sistemi dinamici in forma di stato}
Iniziamo adesso ad approcciare la materia in modo più matematico. Consideriamo il seguente circuito: abbiamo un generatore di tensione $v_G$ che può variare liberamente, e che quindi costituisce l'\textbf{ingresso}, e la tensione del condensatore $v_C$ che invece non è attivamente modificabile, dunque rappresenta lo \textbf{stato interno del sistema}. Possiamo esprimere \textbf{la variazione dello stato interno in funzione di altre grandezze, tra cui l'ingresso.} Vediamo come:
\bb
\begin{minipage}{0.4\textwidth}
\resource{0.6}{circ1}{}
\end{minipage}
\begin{minipage}{0.6\textwidth}
\begin{equation*}
	LKT \rightarrow v_G-v_R-v_C=0
\end{equation*}
ma abbiamo $v_R=iR$ e, dall'equazione caratteristica dei condensatori, $i=C \dot v_C$. Combinando le due, abbiamo:
\begin{equation*}
	v_G-iR-v_C=0 \rightarrow v_G-RC\dot v_C-v_C=0
\end{equation*}
da cui la relazione finale, che lega la \textit{derivata prima di una grandezza, con le altre}:
\begin{equation*}
	\dot v_C(t)=\frac{1}{RC}\paren{v_G(t)-v_C(t)}
\end{equation*}
\end{minipage}
\bb
Procediamo ora chiamando la variabile di stato $x(t)$, e la variabile di ingresso $u(t)$. L'equazione diventa:
\begin{equation*}
	\dot x(t) = -\frac{1}{RC}x(t)+\frac{1}{RC}u(t).
\end{equation*}
Abbiamo però definito un sistema come una terna (ingresso, stato, uscita), per cui \textbf{fissiamo una grandezza che ci misura l'uscita del sistema}. Questa è assolutamente arbitraria, a differenza della variabile di stato. Prendiamo ad esempio $v_R(t)$. Chiamiamo questa $y(t)$. Per definizione di sensore, riusciamo a leggere ora la tensione ai capi della resistenza \textit{istante per istante. }Abbiamo:
\begin{equation*}
	y(t) = v_R(t) =i(t)R = RC\dot v_C(t)=RC\dot x(t)=-x(t)+u(t).
\end{equation*}
Definiamo adesso un modello finale, composto da \textbf{un'equazione che determina la variazione dello stato del sistema $x(t)$ e una che determina, istante per istante, l'uscita $y(t)$ del sistema:}
\begin{equation*}
\begin{dcases*}
	\dot x(t) = -\frac{1}{RC}x(t)+\frac{1}{RC}u(t) \\
	y(t) = -x(t)+u(t)
\end{dcases*}
\end{equation*}
Questa equazione è importante: abbiamo appena descritto un generico sistema fisico utilizzando un modello matematico di questo tipo, denominato \textbf{forma di stato}. Vediamone finalmente la definizione generale.

\newpage
\begin{defin}{Descrizione in \textit{forma di stato} di un sistema}{forma_di_stato}
Per sistemi continui, il tempo $t \in \R$. Diciamo che un sistema dinamico è \textbf{descritto in forma di stato se per esso abbiamo definito la seguente coppia di equazioni}:
\begin{equation}
	\begin{dcases}
		\dot x(t) = f\paren{x(t), u(t), t} \quad \textrm{equazione di stato (ODE I ordine)}\\
		y(t) = h(x(t), u(t), t) \quad \textrm{ equazione di uscita}
	\end{dcases}
\end{equation}
\begin{itemize}
	\item $x(t) \in \R^n$ è la variabile che rappresenta lo \textbf{stato del sistema all'istante $t$}, non direttamente visualizzabile all'esterno \textbf{a meno che non sia direttamente collegato con l'uscita} (la quale è costantemente monitorata mediante sensori, come già detto); 
	\item $u(t) \in \R^m$ è l\textbf{'ingresso del sistema all'istante $t$}, modificabile dall'esterno;
	\item $y(t) \in R^p$ è l'\textbf{uscita del sistema all'istante t}, monitorata da $p$ sensori. 
\end{itemize}
Questo modello matematico è in generale tanto più potente quanto più generale lo riusciamo a mantenere. Il problema a cui però andiamo incontro è la \textit{difficoltà crescente nel calcolo di una soluzione}, che vorremmo mantenere entro certi limiti (eventualmente computazionali).
\end{defin}

Dalla definizione si evince che la rappresentazione in forma di stato è solo in casi particolari di tipo scalare. Il più delle volte, specie all'aumentare della complessità del sistema che si vuole descrivere, si tratta di un sistema di equazioni multidimensionali. In particolare, alla luce delle dimensioni delle tre variabili principali, abbiamo che:
\begin{equation*}
	f:\R^n \times \R^m \times \R \rightarrow \R^n \quad \quad \quad h: \R^n \times \R^m \times \R \rightarrow \R^p
\end{equation*}
Notiamo inoltre che per ogni componente del vettore di $\dot x(t)$ la funzione $f$ dipende da \textbf{tutte le componenti del vettore di $x(t)$}.  Analogo discorso per il vettore $u(t)$. Questo diventa evidente se riscriviamo tutto in forma matriciale:

\begin{defin}{}{}
	\begin{equation*}
		x(t)= \begin{bmatrix}
			x_1(t) \\
			\vdots \\
			x_n(t)
		\end{bmatrix}
		\quad \quad \quad
		\dot x(t)= \begin{bmatrix}
			\dot x_1(t) \\
			\vdots \\
			\dot x_n(t)
		\end{bmatrix}
		\quad \quad \quad
		u(t)= \begin{bmatrix}
			u_1(t) \\
			\vdots \\
			u_m(t)
		\end{bmatrix}
		\quad \quad \quad
		y(t)= \begin{bmatrix}
			y_1(t) \\
			\vdots \\
			y_p(t)
		\end{bmatrix}
	\end{equation*}
	da cui le due equazioni (notare che all'interno di ciascuna $f_j$ o $h_j$ compaiono le intere matrici):
	\begin{equation}
	\label{f_h_matrices}
			\begin{bmatrix}
			\dot x_1(t) \\
			\vdots \\
			\dot x_n(t)
		\end{bmatrix} = \begin{bmatrix}
	f_1\paren{x(t),u(t), t} \\
		\vdots \\
			f_n\paren{x(t), u(t), t}
		\end{bmatrix} \quad \quad \quad 
		\begin{bmatrix}
			y_1(t) \\
			\vdots \\
			y_p(t)
		\end{bmatrix} =
		\begin{bmatrix}
	h_1\paren{x(t),u(t), t} \\
		\vdots \\
			h_p\paren{x(t), u(t), t}
		\end{bmatrix}
	\end{equation}
\end{defin}

Facciamo ora una valutazione più precisa in termini dimensionali. Partiamo innanzitutto col dire che, almeno in questo corso, sarà raro trovare dei sistemi espressi in forma di stato in cui le funzioni $f,h$ sono messe in relazione con $t$. Rimane comunque opportuno specificarla in quando è possibile che ci siano \textit{grandezze che non siano nè stato, nè ingresso} che dipendano dal tempo (si pensi ad una capacità $C(t)$ di un condensatore). Per quanto riguarda le relazioni dimensionali fra le varie grandezze, tipicamente:
\begin{equation*}
	\boxed{p \leq m} \quad \textrm{i.e. numero di uscite $\leq$ numero di ingressi (ragione di costi)},
\end{equation*}
\begin{equation*}
	\boxed{m \leq n} \quad \textrm{i.e. numero di ingressi $\leq$ numero di stati}.
\end{equation*}
In particolare, quando $m < n$ si parla di \textbf{sistema sotto-attuato}, \textbf{sovra-attuato} nel caso opposto, e \textbf{fully-actuated} se $m=n$ (numero di ingressi/attuatori = numero di gradi di libertà). Infine, un caso particolare avviene per i \textbf{sistemi single-input-single-output (SISO)}, in quanto si avrà:
\begin{equation*}
	n>1 \wedge m=p=1.
\end{equation*}
\bb
Abbiamo visto che l'equazione di stato è una ODE di primo ordine, per la quale nativamente esistono infinite funzioni risolutrici. Questo cambia se introduciamo uno \textbf{stato iniziale conosciuto, calcolato ad un istante iniziale} del tipo $x(t_0)=x_0$, in quanto potremmo a quel punto parlare (sotto opportune ipotesi di regolarità di $f$) di un vero e proprio \textbf{problema di Cauchy.} \textbf{Quando ci troviamo in queste condizioni, e vale $u(\tau), \tau \geq t_0$, si parla di sistema causale}, ossia di sistema la cui evoluzione è calcolabile guardando la storia passata del suo stato. (Da TLC sappiamo che si parla invece di sistema \textit{algebrico} quando il suo stato dipende solo dal presente, e non da quanto successo in precedenza). In nessun caso si ha un sistema (che sia reale) dipendente da valori futuri.
\bb
Il numero di variabili di stato dipende ovviamente dal problema fisico che stiamo analizzando, ma in generale può essere \textbf{grosso modo} associato al \textbf{numero di grandezze che compaiono derivate nel tempo} in fase di scrittura delle equazioni del sistema. Potrebbero esserci dei casi in cui la relazione tra VDS e sua derivata non sia di primo grado; in quei caso avremmo una ODE di un ordine necessariamente maggiore del primo. Per ovviare a ciò è opportuno introdurre delle VDS aggiuntive (che di conseguenza andranno ad aumentare la dimensione dello spazio di $x(t)$.
\bb
Nei sistemi dinamici \textit{discreti}  il tempo $t$ non si muove in un dominio continuo, ma è scandito da interi (appunto, discretizzato). La descrizione in forma di stato conterrà, di conseguenza, una ODE a differenze finite (anche detta FDE).

\bb
Gli esempi sulla scrittura di un sistema fisico in forma di stato sono su carta (carrello, auto in moto rettilineo, pendolo).

\section{Traiettoria ed equilibrio}
\begin{defin}{Traiettoria}{traiettoria}
Supponiamo di avere un sistema dinamico \textit{forzato} in forma di stato definito mediante un problema di Cauchy, quindi avente anche stato iniziale specificato:
\begin{equation*}
	\begin{dcases}
		\dot x(t) = f(x(t), u(t), t) \\
		y(t) = h(x(t), u(t), t)
	\end{dcases}, \quad x(t_0)  =x_0
\end{equation*}
È detta \textbf{traiettoria (o moviemento) del sistema} la funzione del tempo 
\begin{equation}
\paren{x(t), u(t)}, \ t \geq t_0
\end{equation}
che \textbf{risolve l'equazione di stato $\dot x(t)$}. In particolare, questa sarà la \textit{traiettoria di stato.} La funzione (della stessa tipologia) che soddisfa l'equazione dell'uscita $y(t)$ è invece detta \textit{traiettoria di uscita.} 
\bb
Senza l'ipotesi di forzatura, la traiettoria dipenderebbe \textit{solo dallo stato iniziale}: $(x(t)), \ t \geq t_0$.
\end{defin}

Dunque, il concetto di traiettoria è legato strettamente a quello di soluzione. Preso un generico sistema \textit{tempo invariante} (per semplicità), con condizione iniziale:
\begin{equation*}
	\begin{dcases}
		\dot x(t) = f(x(t), u(t)) \\
		y(t) = h(x(t), u(t))
	\end{dcases}, \quad x(t_0) = x_0
\end{equation*}
abbiamo che la \textit{traiettoria di stato} è quella funzione che risolve il problema di Cauchy dato dall'equazione di stato e dalla condizione iniziale. In simboli:
\begin{equation*}
	\paren{\bar x(t), \bar u(t)}, \ t\geq t_0 \quad \textrm{traiettoria} \quad \leftrightarrow \quad \begin{dcases}
		\dot{\bar x}(t) = f(\bar x(t), \bar u(t)) \\
		\bar x(t_0) = x_0
	\end{dcases}.
\end{equation*}

\begin{esem}
	Calcoliamo la traiettoria di stato del sistema dinamico avente questa scrittura di stato:
	$$
	\begin{dcases}
	\dot x(t) = u(t) = 1 \\
	x(t_0)=10	
	\end{dcases}
	$$
	Si tratta di un sistema forzato (sono presenti ingressi), per cui la traiettoria sarà necessariamente una funzione a sua volta dipendente dallo stato, quindi scrivibile come $\paren{x(t), u(t)}.$
	Integrando entrambi i membri:
	\begin{equation*}
		x(t) - x(t_0)=\int_{t_0}^{t}u(\tau) \dd{\tau} \rightarrow x(t) = x(t_0)+1(t-t_0) \rightarrow x(t) = 10 + t - t_0.
 	\end{equation*}
 	Abbiamo che la funzione $\paren{x(t), u(t)} = (10 + t-t_0, 1)$ è traiettoria di stato del sistema. Infatti, derivando, si riottiene 1.
\end{esem}

\begin{esem}
	Valutare la traiettoria dato il problema di Cauchy:
	\begin{equation*}
		\begin{dcases}
			\dot x(t) = ax(t)+bu(t) \\
			x(0)=10
		\end{dcases},
		\ con \ u(t) = \bar u \ \forall t \geq 0
	\end{equation*}
	Siamo davanti ad un'equazione differenziale ordinaria lineare non omogenea di primo ordine. La formula risolutiva (valida anche per le omogenee) è la seguente:
	\begin{equation}
		\boxed{\begin{dcases}
			\dot x(t) + a_0(t)x(t)=b(t) \\
			x(t_0) = x_0
			\end{dcases} \quad \longrightarrow \quad x(t) = e^{-A(t)} \sparen{x_0 + \int_{t_0}^t b(t)e^{A(t)}\dd{t}}, \quad \textrm{con} \quad A(t) = \int_{t_0}^t a_0(t)\dd{t}}
	\end{equation}
	Applicata al nostro caso $\dot x-ax=b\bar u$, sapendo che $A(t) = -at$, abbiamo:
	\begin{equation*}
		x(t) = e^{at}\sparen{10+b\bar u\int_0^t e^{-at} \dd{t}} = 10 e^{at}+ b\bar ue^{at}\sparen{-\frac{e^{-at}}{a}}_0^t = 10e^{at} +\frac{b\bar u}{a} e^{at}(-e^{-at}+ 1) = 10e^{at} + \frac{b\bar u}{a}(e^{at} - 1).
	\end{equation*}
\end{esem}

\begin{defin}{Equilibrio}{equilibrio}
	Dato un sistema dinamico \textit{non forzato}, vale che:
	\begin{equation}
		x_e\in \R^n \ \ \textrm{\textbf{equilibrio}} \ \leftrightarrow \ \forall t \geq t_0 \ \ x(t)=x_e \ \ \textrm{è traj.}
	\end{equation}
	In altre parole, si dice che $x_e$ è un equilibrio se la funzione costante associata $x(t) = x_e$ è una \textbf{traiettoria di stato}. In caso di \textit{sistemi invarianti continui}, data la costanza della traiettoria, si avrà  variazione di stato nulla:
	\begin{equation*}
		\dot x(t) = f(x(t)) \xrightarrow[eq.]{}\boxed{f(x_e) = 0}
	\end{equation*}
	Dunque, in corrispondenza di un equilibrio il sistema rimane piantato nello stato in cui si trova.
	\bb
	Nel caso più generale in cui abbiamo un sistema dinamico \textit{forzato}, vale che
	\begin{equation}
			(x_e, u_e)\in \R^n \times \R^m \ \ \textrm{\textbf{coppia di equilibrio}} \ \leftrightarrow \ \forall t \geq t_0 \ \ (x(t), u(t))=(x_e, u_e) \ \ \textrm{è traj.}
	\end{equation}
	e analogamente avremo (sempre per sistemi invarianti) $\boxed{f(x_e,u_e) = 0}$ per gli stessi motivi visti.
\end{defin}
Possiamo dire che $(x_e, u_e)$ è una coppia di equilibrio per un sistema se, applicando l'ingresso $u_e$ in presenza di stato $x_e$, il sistema non si schioda da quello stato.
\begin{lemma}
In caso di sistema in equilibrio, vale che \textbf{anche l'uscita $y(t)$ rimarrà costante ad un valore $y_e$, chiamato uscita di equilibrio.}
\end{lemma}
\begin{lemma}
	In caso di sistemi non invarianti, un equilibrio è tale quando annulla la $f$ per ogni t.
\end{lemma}

\begin{esem}
	Preso l'esercizio sul pendolo (appunti cartacei), calcolare l'equilibrio del sistema ad esso associato (che riportiamo qui a meno dell'equazione di uscita):
	\begin{equation*}
	x \in \R^2, \quad
		\begin{dcases}
			\dot x_1(t) = x_2(t) \\
			\dot x_2(t) = \frac{g}{l}\sin\theta -\frac{b}{Ml^2}x_2(t)+\frac{1}{Ml^2}u(t)
		\end{dcases}
	\end{equation*}
	Abbiamo uno stato in $\R^2$ e un'ingresso scalare, per cui la coppia di equilibrio che bisognerà trovare sarà
	\begin{equation*}
		(x_e, u_e) \quad \textrm{con} \quad x_e \in \R^2, \ u_e \in \R.
	\end{equation*}
	 Notiamo anche che il sistema è tempo invariante, in quanto non compare alcuna dipendenza dal tempo scorrelata da stato ed ingresso, per cui possiamo utilizzare la considerazione che \textbf{in presenza di un equilibrio vale:}
	\begin{equation*}
		f(x_e,u_e) = 0 \quad \rightarrow \quad  \begin{bmatrix}
			x_{e2} \\ \frac{g}{l}\sin\theta -\frac{b}{Ml^2}x_{e2}+\frac{1}{Ml^2}u_e
		\end{bmatrix} = \begin{bmatrix}
			0 \\ 0
		\end{bmatrix}
	\end{equation*}
	Eseguendo i calcoli otteniamo:
	\begin{equation*}
		\begin{dcases}
			x_{e2} = 0 \\
			u_e = - Mlg\sin\theta 
		\end{dcases}
	\end{equation*}
\end{esem}

\section{Classificazioni}
Prima di vedere i concetti matematici, raggruppiamo i sistemi che ci possono capitare secondo queste considerazioni (indichiamo prima la classe generale, poi una sua sottoclasse particolare):
\begin{itemize}
	\item \textbf{multivariabili (MIMO) o monovariabili (SISO)} \rarr nel secondo caso abbiamo una dimensione del vettore di ingressi e di quello delle uscite pari ad 1: $$ \dim{u(t)} = m = \dim{y(t)} = p = 1.$$ 
	\item \textbf{propri o strettamente propri} \rarr nei \textbf{primi} vale l'espressione generale della forma di stato, in particolare \textbf{l'uscita dipende direttamente dagli ingressi} (c'è ovviamente anche la dipendenza con lo stato ed, eventualmente, con il tempo $t$); nei \textbf{secondi} invece \textbf{l'uscita $y(t)$ non dipende direttamente dagli ingressi}, per cui la funzione $h$ sarà del tipo:
	\begin{align*}
		y(t) = h(x(t),t).
	\end{align*}
	Il vantaggio dei sistemi strettamente propri è che, per il calcolo dell'uscita è obbligatorio passare per l'equazione differenziale, e questa tipicamente si comporta come un \textit{filtro}. Questo non accade nei propri, in quanto vale $y(t) = h(x(t), \mathbf{u(t)}, t)$. Dunque, questa azione filtrante non c'è e, se per esempio ci fossero delle discontinuità in in, queste potrebbero apparire anche in out.
	
\resource{0.8}{propri}{Questo sistema è composto da una parte strettamente propria (cerchiata), in cui l'uscita non dipende direttamente dagli ingressi; presenta tuttavia una componente in basso che invece ha una dipendenza diretta. Di conseguenza, visto in toto, è proprio.}
\end{itemize}

\begin{itemize}
	\item \textbf{forzati o non forzati} \rarr questi ultimi \textbf{non ammettono ingressi, per cui evolvono per conto proprio}:
		\begin{equation*}
		\begin{dcases}
			\dot x(t)=f(x(t), t) \\
			y(t)=h(x(t),t)
		\end{dcases}
\end{equation*} 
	 Nei forzati, invece, gli ingressi sono significativi. È una definizione più stringente rispetto a quella vista per i sistemi propri o strettamente propri, in quanto in questo caso l'eventuale non dipendeza \textit{non riguarda solo l'equazione di uscita, ma anche quella di stato}:
A noi interessa progettare \textit{sistemi di controllo, capaci di modificare opportunamente gli ingressi per ottenere un certo comportamento.} È ovvio che quindi il focus verterà sui sistemi forzati.
\item\textbf{tempo varianti ed invarianti} \rarr in questi ultimi \textbf{le funzioni di stato e uscita $f, h$ non dipendono esplicitamente dal tempo $t$}, per cui si presenteranno in questa forma (questa cosa è dimostrabile):
\begin{equation*}
\begin{dcases}
		\dot x(t) = f(x(t), u(t)) \\
		y(t) =  h(x(t), u(t))
\end{dcases}
\end{equation*}
il che significa che tutti i parametri che non siano stato e ingressi all'interno delle funzioni suddette si comportano in modo \textit{costante.}
Inutitivamente, un sistema tempo invariante \textbf{si comporterà, a parità di ingressi, in modo identico indipendentemente da quando viene azionato}. In altre parole, se un ingresso $k(t)$ genera un'uscita $z(t)$, allora per ogni ingresso ritardato del tipo $k(t+\Delta)$ si otterrà un uscita $z(t+\Delta),$ ossia ritardata dello stesso quantitativo temporale.
\item \textbf{non lineari e lineari} \rarr in questi ultimi \textbf{entrambe le equazioni di stato ed uscita dipendono linearmente dallo stato e dall'ingresso, dunque sono scrivibili come combinazioni lineari degli elementi di $x(t)$ e di $u(t)$}. Simbolicamente (viene omessa la dipendenza dal tempo per brevità):
\begin{align}
	\label{f_lineare}
	f = \begin{bmatrix}
		f_1(x, u, t) \\
		\vdots \\
		f_n(x, u, t)
	\end{bmatrix} \quad \textrm{con} \quad f_j(x,u,t) & = a_{j1}(t)x_1(t) + \cdots + a_{jn}(t)x_n(t) + b_{j1}(t)u_1(t) + \cdots + b_{jm}(t)u_m(t)
\end{align}
\begin{align}
\label{h_lineare}
		h = \begin{bmatrix}
		h_1(x, u, t) \\
		\vdots \\
		h_p(x, u, t)
	\end{bmatrix} \quad \textrm{con} \quad h_k(x,u,t) & = c_{k1}(t)x_1(t) + \cdots + c_{kn}(t)x_n(t) + d_{k1}(t)u_1(t) + \cdots + d_{km}(t)u_m(t)
\end{align}
con $j \in \{1,2, \cdots, n\}$ e $k \in \{1,2, \cdots, p\}$.
\end{itemize} 


\section{Stabilità di uno stato di equilibrio e di una traiettoria}
\begin{prop}
Dato un sistema avente \textbf{ingresso fissato ad un valore $u_e$},
questo solo apparentemente è forzato: \textbf{non potendo cambiare l'ingresso}, è possibile \textbf{vederlo, almeno concettualmente, come un non forzato.} Nei prossimi concetti si supporrà di lavorare in questa situazione:
\begin{equation*}
	\dot x(t) = f(x(t), u_e) \quad \rightsquigarrow \quad  \dot x(t) = f(x(t)).
\end{equation*}
\end{prop}
Abbiamo visto che $(x_e, u_e)$ è una coppia di equilibrio per un sistema quando annullano la funzione $f$. In particolare, applicando un ingresso $u_e$ ad un sistema avente stato iniziale $x_e$, l'evoluzione del sistema è stazionaria.
\begin{equation*}
	(x_e, u_e) \quad  \textrm{equilibrio} \quad \rightarrow \quad \dot x(t) = f(x_e, u_e) = 0 \quad \textrm{cioè} \quad x(t) = x_e \ \forall t.
\end{equation*} Cosa succede se, però, invece di partire all'equilibrio, partissi da un punto $x(0)$ situato \textbf{vicino ad esso?} 
\begin{equation*}
	 \boxed{x(0)=x_e+\Delta x_0} \quad \rightarrow \quad  x(t) = \ ?
\end{equation*}


\begin{defin}{Equilibrio stabile ed instabile}{}
Uno stato di equilibrio $x_e$ si dice \textbf{stabile} se:
\begin{equation}
	\forall \epsilon > 0 \ \ \exists \delta > 0 \ \ : \ \ \forall x_0 \ \textrm{con} \ \norm{x_0 - x_e} \leq \delta \ \textrm{risulta} \ \norm{x(t) - x_e} \leq \epsilon \ \forall t.
\end{equation} 	
A parole: per ogni intorno di $x_e$ di raggio $\epsilon$ piccolo a piacere, è possibile prendere un intorno di raggio $\delta$ da $x_e$ e, se $x_e$ è stabile, \textbf{partendo da un qualsiasi punto $x_0$ che disti da $x_e$ meno di $\delta$} (i.e. prendendo qualunque punto $x_0$ all'interno dell'intorno di raggio $\delta$), \textbf{la traiettoria per tutti i tempi successivi rimane sempre nell'intorno di raggio $\epsilon$.}
\bb
Se invece $x_e$ è \textbf{instabile}, non vale quanto detto, i.e. possiamo prendere un intorno di raggio $\epsilon$ e, comunque si scelga un secondo intorno di raggio $\delta$, esiste un punto $x_0$ all'interno di quest'ultimo tale che, \textbf{la sua traiettoria per un qualche istante di tempo $t$} (al limite, per ogni $t$) \textbf{esce dall'intorno di raggio $\epsilon$.}
\begin{equation*}
	\exists \epsilon > 0 \ \ \forall \delta > 0 \ \ \textrm{in cui} \ \ \exists x_0 \ \textrm{con} \ \norm{x_0 - x_e} \leq \delta \ \ \textrm{tale per cui} \ \ \exists t \ : \ \norm{x(t) - x_e} > \epsilon.
\end{equation*} 
\end{defin}
\textbf{Osservazione:} Perché considerare due intorni uno dentro l'altro? Perché potrebbero esistere punti all'interno di $\epsilon$ la cui traiettoria nel tempo \textit{non rimane confinata in $\epsilon$ stesso!}
\begin{defin}{Equilibrio attrattivo}{}
Uno stato di equilibrio $x_e$ si dice \textbf{attrattivo} se:
\begin{equation}
	\exists \delta > 0 \ \ : \ \ \forall x_0 \ \textrm{con} \ \norm{x_0 - x_e} \leq \delta \ \textrm{risulta} \ \llimit{t}{\pinf}{\norm{x(t)-x_e}} = 0.
\end{equation}	
A parole: per ogni intorno di $x_e$ di raggio $\delta$ piccolo a piacere, è possibile prendere \textbf{un qualsiasi punto $x_0$ all'interno di questo intorno} e, se $x_e$ è attrattivo, \textbf{all'infinito la traiettoria $x(t)$ convergerà verso $x_e$ stesso.} 
\bb
Attenzione! Questa definizione non dice niente sul comportamento della traiettoria nel corso del tempo: potrà anche allontanarsi di 3000km da $x_e$; se all'infinito convergerà verso quest'ultimo, sarà attrattivo (in altre parole, non c'è un intorno di raggio $\epsilon$ all'interno del quale la traiettoria deve rimanere sempre confinata).
\end{defin}
Dunque, partendo da un punto $x(0)$ vicino all'equilibrio $x_e$ si hanno comportamenti diversi: se la sua traiettoria $x(t)$, per tutti i tempi successivi, rimane confinata entro un intorno vicino ad $x_e$, si ha la \textbf{stabilità}; se invece per $t \rightarrow \pinf$ andrà a convergere verso $x_e$ (nel frattempo potrà fare quello che vuole) si ha \textbf{attrattività}. 
\bb
\begin{defin}{Equilibrio asintoticamente stabile}{}
	Uno stato di equilibrio $x_e$ si dice \textbf{asintoticamente stabile} se è \textbf{stabile e attrattivo}. Questo significa che, preso un intorno di raggio $\epsilon$ da $x_e$, un \textbf{qualsiasi punto} $x(0)$ all'interno di un intorno di raggio $\delta$ da $x_e$, godrà di una traiettoria $x(t)$ che resterà \textbf{confinata per ogni $t$ entro l'intorno di raggio $\epsilon$}, e che \textbf{per $t \rightarrow \pinf$} convergerà verso $x_e$. In simboli:
	\begin{equation*}
		\forall \epsilon > 0 \ \ \exists \delta > 0 \ \ : \ \ \forall x_0 \ \textrm{con} \ \norm{x_0 - x_e} \leq \delta \ \textrm{risulta} \ \norm{x(t) - x_e} \leq \epsilon \ \forall t \ \textrm{e} \llimit{t}{\pinf}{\norm{x(t)-x_e}} = 0.
	\end{equation*}
	Questa situazione ci piace particolarmente! L'obiettivo sarà infatti progettare sistemi di controllo che generino questo tipo di comportamento, i.e. convergente verso, appunto, una stabilità.
\end{defin}
\bb
\textbf{Osservazione:} Nelle definizioni di stabilità (asintotica o meno), abbiamo dato per scontato che l'intorno di raggio $\delta$ sia contenuto all'interno di quello di raggio $\epsilon$. Questo ha senso: Se l'intorno di raggio $\delta$ fosse più grande, potremmo prendere un punto al suo interno che, ancor prima di partire, si trova già al di fuori dall'intorno di raggio $\epsilon$. La proprietà di stabilità sarebbe già falsa. 
\bb
\textbf{Osservazione:} Quelle definite finora sono stabilità \textit{locali}, in quanto hanno valore vicino all'equilibrio $x_e$. È possibile ottenere le rispettive \textbf{definizioni globali rimuovendo i vincoli dipendenti da $\delta$ (dominio di attrazione), e quindi supponendo $x$ libero di variare nel suo dominio di definizione, che nel caso generale è $\R^n.$}
\bb
Quanto visto vale anche per una intera \textit{traiettoria}, non solo per un singolo punto $x_e$. Vediamo per brevità soltanto la definizione di \textit{asintoticamente stabile} (che comprende le altre).
\begin{defin}{Traiettoria asintoticamente stabile}{}
Una traiettoria per un sistema dinamico $\bar x(t), \ t \geq t_0$ si dice \textbf{asintoticamente stabile} se è \textbf{stabile ed attrattiva}, ossia, in simboli:
\begin{itemize}
	\item \textbf{stabilità} \rarr \ $\forall \epsilon > 0 \ \  \exists \delta > 0 \ \ : \ \ \forall t_\delta \ \textrm{con} \ \norm{t_\delta - t_0} \leq \delta \ \textrm{risulta} \ \norm{x(t)_\delta -\bar x(t)} \leq \epsilon$; 
	\item \textbf{attrattiva} \rarr $\exists \delta > 0 \ : \ \forall t_\delta \ \textrm{con} \ \norm{t_\delta - t_0} \leq \delta \ \textrm{risulta} \ \displaystyle \llimit{t}{\pinf}{\norm{x(t)_\delta -\bar x(t)}} = 0$.
\end{itemize}
A parole, vale la proprietà per $\bar x(t)$ se, scelto un intorno di raggio $\epsilon$ della traiettoria e un intorno $\delta$ della condizione iniziale $t_0$, partendo da un generico punto $t_\delta$ all'interno dell'intorno $\delta$ \textbf{la traiettoria che ne deriverà resterà confinata per ogni $t$ entro l'intorno di raggio $\epsilon$ della traiettoria di partenza e, per $t \rightarrow \pinf$, andrà a convergere verso $\bar x(t)$.}
\end{defin}

\chapter{Sistemi dinamici lineari}
Vediamo ora un caso particolare di sistemi dinamici: è chiaro che più particolarizziamo, più si va incontro ad una semplificazione dei modelli matematici necessari per la descrizione del sistema. Questa semplificazione è direttamente proporzionale alla semplicità di studio. Più uno studio è semplice, più cose riusciremo a dire al riguardo.
\bb
Un grande vantaggio di cui godono i sistemi lineari è quello di poter essere descritti completamente in \textit{forma matriciale.} Infatti, alla luce di quanto visto in \eqref{f_h_matrices}, e riprendendo le scritture in forma di combinazioni lineari \eqref{f_lineare} e \eqref{h_lineare}, definiamo la

\begin{defin}{Scrittura in forma matriciale di un sistema lineare}{}
	Vediamo l'equazione di stato:
	\begin{align}
		\begin{cases}\underbrace{\begin{bmatrix}
			\dot x_1(t) \\
			\vdots \\
			\dot x_n(t)
		\end{bmatrix}}_{(n\times 1)} = 
		\underbrace{\begin{bmatrix}
			a_{11}(t) & a_{12}(t) & \cdots &a_{1n}(t) \\
			\vdots & \vdots & \ddots & \vdots \\
			a_{n1}(t) & a_{n2}(t) & \cdots &a_{nn}(t)
		\end{bmatrix} \begin{bmatrix}
			x_1(t) \\ \vdots \\ x_n(t)
		\end{bmatrix}}_{(n \times n)(n\times 1) \rightarrow (n\times 1)} + \underbrace{\begin{bmatrix}
			b_{11}(t) & b_{12}(t) & \cdots &b_{1m}(t) \\
			\vdots & \vdots & \ddots & \vdots \\
			b_{n1}(t) & b_{n2}(t) & \cdots &b_{nm}(t)
		\end{bmatrix} \begin{bmatrix}
			u_1(t) \\ \vdots \\ u_m(t)
		\end{bmatrix}}_{(n \times m)(m\times 1) \rightarrow (n\times 1)}
\\
\\
		\underbrace{
			\begin{bmatrix}
			y_1(t) \\ \vdots \\ y_p(t)
			\end{bmatrix}}_{(p\times 1)} = 
		\underbrace{\begin{bmatrix}
			c_{11}(t) & c_{12}(t) & \cdots &c_{1n}(t) \\
			\vdots & \vdots & \ddots & \vdots \\
			c_{p1}(t) & c_{p2}(t) & \cdots &c_{pn}(t)
		\end{bmatrix} \begin{bmatrix}
			x_1(t) \\ \vdots \\ x_n(t)
		\end{bmatrix}}_{(p \times n)(n\times 1) \rightarrow (p\times 1)} + \underbrace{\begin{bmatrix}
			d_{11}(t) & d_{12}(t) & \cdots &d_{1m}(t) \\
			\vdots & \vdots & \ddots & \vdots \\
			d_{p1}(t) & d_{p2}(t) & \cdots &d_{pm}(t)
		\end{bmatrix} \begin{bmatrix}
			u_1(t) \\ \vdots \\ u_m(t)
		\end{bmatrix}}_{(p \times m)(m\times 1) \rightarrow (p\times 1)}
		\end{cases}
\end{align}
	Assegnando dei nomi a queste matrici, otteniamo una scrittura elegante della \textbf{forma di stato per un sistema lineare tempo variante}:
	\begin{equation}
		\begin{cases}
			\dot x(t) = A(t)x(t) + B(t)u(t) \\
			y(t) = C(t)x(t) + D(t)u(t)
		\end{cases}
	\end{equation}
	con $A(t) \in \mathcal{M}(n,n,\R)$, $B(t) \in \mathcal{M}(n,m,\R)$, $C(t) \in \mathcal{M}(p,n,\R)$, $D(t) \in \mathcal{M}(p,m,\R)$.
Dunque, se il modello che traggo dall'analisi di un sistema è lineare, posso \textbf{descriverlo completamente mediante le quattro matrici} descritte sopra ($A,B$ per lo stato; $C,D$ per l'uscita).
\end{defin}

\begin{defin}{LTI - Sistemi lineari \textit{tempo invarianti}}{}
	La definizione vista sopra si semplifica ulteriormente nel caso in cui il SL sia \textbf{tempo invariante} (\textbf{sistema LTI}), in quanto in quel caso solo stato e ingressi presenteranno una dipendenza col tempo, col risultato che $A,B,C,D$ diventeranno matrici \textit{di coefficienti:}
\begin{equation}
\label{eq:lti}
		\begin{cases}
			\dot x(t) = Ax(t) + Bu(t) \\
			y(t) = Cx(t) + Du(t)
		\end{cases}
\end{equation}
Le dimensioni delle matrici restano tali.
\end{defin}
\begin{defin}{LTI SISO}{}
Molto comuni in questo corso saranno gli \textbf{LTI SISO} (dunque con $m=p=1$). L'equazione sarà analoga a quella vista per gli LTI generici \eqref{eq:lti}; cambierà però la dimensione delle varie matrici:
\begin{align*}
\begin{cases}
\underbrace{\begin{bmatrix}
			\dot x_1(t) \\
			\vdots \\
			\dot x_n(t)
		\end{bmatrix}}_{(n\times 1)} = 
		\underbrace{\begin{bmatrix}
			a_{11} & a_{12} & \cdots &a_{1n} \\
			\vdots & \vdots & \ddots & \vdots \\
			a_{n1} & a_{n2} & \cdots &a_{nn}
		\end{bmatrix} \begin{bmatrix}
			x_1(t) \\ \vdots \\ x_n(t)
		\end{bmatrix}}_{(n \times n)(n\times 1) \rightarrow (n\times 1)} + \underbrace{\begin{bmatrix}
			b_{11} \\ \vdots \\ b_{n1} 
		\end{bmatrix} u(t)}_{(n \times 1)(1\times 1) \rightarrow (n\times 1)}
\\
\\
		\underbrace{
			y(t)}_{(1\times 1)} = 
		\underbrace{\begin{bmatrix}
			c_{11} & c_{12} & \cdots &c_{1n}
		\end{bmatrix} \begin{bmatrix}
			x_1(t) \\ \vdots \\ x_n(t)
		\end{bmatrix}}_{(1 \times n)(n\times 1) \rightarrow (1\times 1)} + \underbrace{
			d_{11} u(t)}_{(1 \times 1)(1\times 1) \rightarrow (1\times 1)}
\end{cases}
\end{align*}
con $A \in \mathcal{M}(n,n, \R)$, $B \in \mathcal{M}(n,1, \R)$, $C \in \mathcal{M}(1,n, \R)$, $D \in \mathcal{M}(1,1, \R)$.
\end{defin}



\section{Principio di sovrapposizione degli effetti}
Attenzione! Vediamo ora questa proprietà riferita alla rappresentazione di un sistema dinamico lineare mediante\textit{ forma di stato}, ma questa continuerà a valere anche per altri modelli matematici che vedremo successivamente.
\bb
\begin{defin}{}{}
\textbf{Attenzione! Valida solo per sistemi lineari, sia tempo varianti che invarianti.}
	\bb
	Consideriamo il sistema lineare seguente
	\begin{equation*}
	\begin{cases}
		\dot x(t) = A(t)x(t) + B(t)u(t) \\
		y(t) = C(t)x(t) +D(t)u(t)
	\end{cases}
	\end{equation*}
	e supponiamo di avere \textbf{due traiettorie} per esso (i.e. evoluzioni stato-ingresso che soddisfano l'equazione di stato):
	\begin{equation*}
		(x_a(t), u_a(t))\quad traj \ con \quad  x_a(t_0)=x_{0a},
	\end{equation*}
		\begin{equation*}
		(x_b(t), u_b(t))\quad traj \ con \quad x_b(t_0)=x_{0b}.
	\end{equation*}
Allora, \textbf{la combinazione lineare delle due genera una nuova traiettoria} per il sistema, ossia una nuova soluzione per l'equazione di stato. $\forall \alpha, \beta \in \R$
	\begin{equation}
		(x_{ab}(t), u_{ab}(t)) = (\alpha x_a(t)+\beta x_b(t), \alpha u_a(t) + \beta u_b(t)) \quad traj \ con \quad x_{ab}(t_0) = \alpha x_{0a} + \beta x_{0b}.
	\end{equation}
\textbf{Osservazione:} quanto visto vale identicamente per l'uscita: prese due traiettorie per l'uscita, la combinazione lineare delle due genera una nuova traiettoria di uscita per il sistema.
\end{defin}

\begin{esem} Prendiamo un LTI avente stato bidimensionale e condizioni iniziali $x_1(0) = x_{1,0}$ e $x_2(0) = x_{2,0}$:
	\begin{equation*}
		\begin{cases}
			\dot x_1(t)=x_2(t) \\
			\dot x_2(t) = u(t)
		\end{cases} \quad \rightarrow \quad  \dot x(t) = \begin{bmatrix}
			0 & 1 \\ 0 & 0
		\end{bmatrix}\begin{bmatrix}
		x_1(t) \\ x_2(t) \end{bmatrix}+\begin{bmatrix}
			0 \\ 1
		\end{bmatrix} u(t) = Ax(t)+Bu(t).
	\end{equation*}
\subsubsection{Traiettoria A}
Consideriamo $u_a (t) = 3$, $t \geq 0$, e una condizione iniziale per lo stato del tipo $x(0) = \begin{bmatrix}
	2 \\ 0
\end{bmatrix}$. Integrando da $0 $ a $t$ ciascuna componente dello stato, troviamo:
\begin{equation*}
	x_2(t)- x_2(0) = \int_0^t u(t)\dd{t} \ \rightarrow \ x_2(t) = 3t
\end{equation*}
\begin{equation*}
	x_1(t) -x_1(0) = \int_0^t x_2(t)\dd{t} \ \rightarrow \ x_1(t) = 2+\frac{3}{2}t^2
\end{equation*}
Definiamo dunque:
\begin{equation*}
\boxed{
	Traj \ A =(x_A(t), u_A(t)) = \paren{\begin{bmatrix}
		2+\frac{3}{2}t^2 \\ 3t
	\end{bmatrix}, 3}}
\end{equation*}
È una traiettoria perché se la infiliamo all'interno del sistema definito all'inizio, lo soddisfa.

\subsubsection{Traiettoria B}
Consideriamo $u_b(t) = \cos(t)$, $t \geq 0$, e una condizione iniziale per lo stato $x(0) = \begin{bmatrix}
	3 \\ 1
\end{bmatrix}$. Integrando:
\begin{equation*}
	x_2(t) = 1+\sin(t) \quad \quad x_1(t) =3è+\int_0^t1+\sin(t)\dd{t} = 3
	+t+[-\cos(t)]^t_0 = 3+t-\cos(t) + 1 = 4+t-\cos(t).
\end{equation*}
Definiamo dunque:
\begin{equation*}
	\boxed{Traj \ B = (x_b(t), u_b(t)) = \paren{\begin{bmatrix}
		4+t-\cos(t) \\ 1+\sin(t)
	\end{bmatrix}, \cos(t)}}
\end{equation*}

\subsubsection{La combinazione delle traiettorie A, B sarà ancora una traiettoria?}
Consideriamo  $x_{ab} = \alpha x_a + \beta x_b$ e $u_{ab} = \alpha u_a + \beta u_b$.  Nel nostro caso, avremo:
\begin{equation*}
	Traj \ C = (x_{ab}(t), u_{ab}(t)) = \paren{\begin{bmatrix}
		\alpha(2+\frac{3}{2} t^2) + \beta(4+t-\cos(t)) \\ 3\alpha t + \beta(1+\sin(t))
	\end{bmatrix}, 3\alpha+\beta \cos(t) }
\end{equation*}
Questa è una traiettoria? Dovrebbe risolvere l'equazione di stato $\forall \alpha, \beta \in \R$:
\begin{align*}
	\dot x_2(t) = 3\alpha +\beta \cos (t) = u(t) \rightarrow yes \quad \quad \dot x_1(t) = 3\alpha t +\beta +\beta \sin(t) = x_2(t) \rightarrow yes
\end{align*}
E infatti la risolve. Dunque la sovrapposizione funziona.
\end{esem}
%\textbf{Attenzione!} Quanto visto è stato applicato solamente all'equazione di stato (e quindi considerando la \textit{traiettoria di stato}), ma vale in modo analogo anche per la \textit{traiettoria di uscita}, ossia della funzione del tipo $(x(t), u(t))$ che soddisfa $y(t)$.

\section{Traiettoria come somma di due evoluzioni}
\label{sec:traj_somma_evoluz}
\begin{defin}{}{}
Utilizzando il principio di sovrapposizione, vale che \textbf{fissato uno stato inziale $x(t_0) = x_0$ e applicando un ingresso $u(t)$, $t \geq t_0$, è possibile scrivere la traiettoria di stato di un sistema lineare (tempo variante od invariante) come somma di due traiettorie:}
\begin{equation}
	x(t) = x_L(t) +x_F(t)
\end{equation}
dove:
\begin{itemize}
	\item  $x_L(t)$, $t \geq t_0$ è la traj. di stato ottenuta \textbf{partendo con uno stato iniziale diverso da zero ed ingresso nullo}, i.e. $x_L(t_0) = x_0$ e $u_L(t) = 0 \ \forall t \geq t_0$ \rarr \textbf{evoluzione libera};
	\item $x_F(t)$, $t \geq t_0$ è la traj di stato ottenuta \textbf{partendo con uno stato iniziale nullo ed un ingresso diverso da zero}, i.e. $x_F(t_0) = 0$ e $u_F(t) = u(t) \ \forall t \geq t_0$ \rarr \textbf{evoluzione libera.}
\end{itemize}
\textbf{Osservazione:} quanto visto vale anche per l'equazione di uscita:
\begin{equation}
y(t) = y_L(t) è+ y_F(t)
\end{equation}
\end{defin}
Abbiamo scoperto che è possibile ottenere una generica traettoria per un SL \textbf{perturbando l'equilibrio prima mediante cambiamento di stato iniziale,  tenendo fermo l'ingresso (evoluzione libera)}, e poi \textbf{tenendo fermo all'equilibrio lo stato iniziale, applicando un ingresso (evoluzione forzata).} 

\begin{prop}
\label{prop:sl_coppia_nulla_eq}
	Consideriamo un sistema lineare, quindi definito da un'equazione di stato del tipo $\dot x(t) = A(t)x(t) + B(t)u(t).$ Supponendo ingresso nullo (dunque $u(t) = 0$)  e stato nullo ($x(t)=0$), allora si vede che l'intera ED si annulla: $\dot x(t) = f(x(t), u(t), t) = 0 \quad \forall t$. Questa è la definizione di \textbf{equilibrio.} In particolare, vale che \textbf{per un sistema lineare la coppia  $(x_e,u_e) = (0,0)$} \textbf{è sempre di equilibrio}, ed è un caso particolare  in cui il sistema non fa niente per sempre.
\end{prop}

\section{Sistemi dinamici lineari tempo invarianti (LTI)}

\subsection{Equazioni delle traiettorie nel caso scalare e generale}
\label{subsec:eq_traj_lti_scalare_gen}
Se supponiamo di avere un sistema LTI \textit{scalare}, i.e. con $x(t),y(t),u(t) \in \R$, possiamo \textbf{esprimere esplicitamente le equazioni di traiettoria, sia dello stato, che dell'uscita}, mediante la risoluzione dell'equazione differenziale dello stato tramite la formula riquadrata vista qualche pagina fa:
\begin{align*}
	\begin{dcases}
	\dot x(t) = ax(t) + bu(t) \\
	x(0) = x_0
	\end{dcases} \ \rightarrow \ \boxed{x(t) =e^{at}x_0+\underbrace{\int_0^te^{a(t-\tau)}bu(\tau)\dd{\tau}}_{int. \ di \ convoluzione}}
\end{align*}
Lo stato inizia da $t= 0$ quindi l'estremo inferiore dell'integrale è $t_0  = 0.$ Otteniamo poi l'espressione dell'uscita semplicemente sostituendo l'equazione riquadrata al posto di $x(t)$:
\begin{align*}
	y(t) = cx(t) +du(t) \ \rightarrow \ \boxed{y(t) = ce^{at}x_0+c\int_0^te^{a(t-\tau)}bu(\tau)\dd{\tau} + du(t)}
\end{align*}
\bb
È possibile estendere queste equazioni al \textbf{caso generale, i.e. un sistema LTI con $x \in \R^n$, $y \in \R^p, u \in \R^m$?} Sì, a patto che definiamo cosa vuol dire \textit{calcolare l'esponenziale di una matrice}. Questo perché quello che nel caso precedente era $a$, adesso è una matrice!
\begin{equation*}
	e^{at} = 1+at + \frac{(at)^2}{2!} + \cdots  \quad \longrightarrow \quad e^{At} = I+ At+\frac{(At)^2}{2!} + \cdots 
\end{equation*}
Fortunatamente, l'elevamento a potenza è un'operazione inclusa nello spazio delle matrici \textbf{quadrate} (e infatti la matrice A è sempre quadrata $n\times n$), in quanto è semplicemente un prodotto. Posso dunque definire l'equazione di una generica traiettoria anche nel caso generale:
\begin{align*}
	\boxed{x(t) =e^{At}x_0+\int_0^te^{A(t-\tau)}Bu(\tau)\dd{\tau} \quad \quad y(t) = Ce^{At}x_0+C\int_0^te^{A(t-\tau)}Bu(\tau)\dd{\tau}  + Du(t)}	
\end{align*}
Notiamo che anche da un punto di vista dimensionale le cose tornano: $e^{At}$ è una somma infinita di matrici $n \times n$, dunque se questa serie converge il risultato è ancora una $n \times n$; $x_0$ è un vettore $n \times 1$ (perché è una condizione iniziale dello stato, che è in $\R^n$). Il loro prodotto è quindi $n \times 1$, compatibile con $x(t)$. Si dimostra che anche l'integrale di convoluzione è coerente.
\bb
\textbf{Nota!} Questa definizione di traiettoria rispecchia alla perfezione quanto è stato detto sulla traiettoria sistemi lineari, scrivibile come somma di due componenti. Guardando $x(t)$, vediamo che il primo termine, indipendente dall'ingresso, rappresenta l'\textit{evoluzione libera}; l'integrale di convoluzione quella \textit{forzata}. Questo è \textbf{potentissimo! L'evoluzione libera di un sistema LTI non scalare dipende solo ed unicamente dall'esponenziale di una matrice}. Se riuscissimo a capire il \textbf{comportamento di questo esponenziale} potremmo capire \textbf{l'evoluzione libera di un LTI forzato, o l'evoluzione in toto di un sistema lineare non forzato!}
\subsubsection{Cenni sulla rappresentazione in forma di Jordan di una matrice}
Calcolare l'esponenziale di una matrice definito come somma di infiniti termini non è però fattibile. Fortunatamente, mediante la \textbf{rappresentazione di Jordan} delle matrici, questo calcolo si traduce in un concetto molto più semplice, e soprattutto, finito. Diamo qualche risultato preliminare.
Partiamo con delle definizioni preliminari:
\begin{prop}
	Sia $M \in \mathcal{M}(n,n,\mathbb{K})$ e sia $\lambda_0$ un suo autovalore. Si chiama:
	\begin{itemize}
		\item \textbf{molteplicità algebrica} di $\lambda_0$  \rarr \textbf{il numero che esprime quante volte $\lambda_0$ annulla il polinomio caratteristico} associato ad $M$. La somma delle molteplicità algebriche \textbf{non può mai superare l'ordine della matrice};
		\item \textbf{molteplicità geometrica} di $\lambda_0$ \rarr la \textbf{dimensione dell'autospazio generato da $\lambda_0$, calcolato come $n - \rank{(M-\lambda_0 I)}$.} Le nozioni sul rango non vengono riprese qui.
	\end{itemize}
	Sottolineiamo inoltre la relazione
\begin{equation}
		1 \leq m_g(\lambda_0) \leq m_a(\lambda_0)\leq n.
	\end{equation} 
\end{prop}


\begin{defin}{Forma canonica di Jordan}{}
Sia $M \in \mathcal{M}(n,n,\mathbb{K}).$ Se ad $M$ sono associati \textbf{autovalori tutti esistenti in $\mathbb{K}$}, allora è possibile rappresentarla in un'altra matrice $J$, detta in forma di Jordan, mediante il cambiamento di base:
\begin{align*}
	M = TJT^{-1}.
\end{align*}
$J$ è una matrice \textbf{diagonale a blocchi} strutturata in questo modo:
	\begin{itemize}
		\item lungo la diagonale principale sono presenti \textbf{tutti gli autovalori di $M$ contati con la loro molteplicità algebrica};
		\item tutti gli autovalori uguali tra di loro consecutivi sulla diagonale formano un \textbf{blocco di Jordan}. Avremmo quindi \textbf{un numero di blocchi sulla diagonale pari al numero di autovalori distinti;}
		\item Ciascun blocco di Jordan è composto da un \textbf{numero di box di Jordan pari alla molteplicità geometrica di quell'autovalore}. Se un blocco è di dimensioni maggiori di $1\times 1$, allora è necessario aggiungere degli 1 sopra la diagonale principale (solamente di quello specifico blocco). Se la molteplicità algebrica e geometrica non ci consente di prendere in modo univoco i box di Jordan, è necessario procedere con il calcolo di dimensioni elevate ad esponenti incrementali, fin quando non si è in condizioni non ambigue in termini di scelta delle box.\footnote{i.e. $m.g. = \dim({\ker{(M-\lambda_0 I)^k})},$ che lega la molteplicità geometrica al calcolo esplicito di una dimensione.}
	\end{itemize}
\end{defin}
Non andiamo oltre su questo argomento, in quanto le formule della pagina precedente non saranno mai utilizzate, in questo corso, in forma analitica (ci aiuterà MATLAB a risolverle), ma soprattutto perché \textbf{ci interessa relativamente quale sia l'equazione specifica della traiettoria di un sistema LTI: quello che ci interessa è come si comporta - all'incirca - al trascorrere del tempo.} Vediamo ora come fare per scoprirlo senza passare per tutti questi concetti non affatto banali.
\subsection{Traiettoria come combinazione di modi naturali}
Il comportamento del sistema nel corso del tempo lo si può approssimare grazie ai modi naturali e ai risultati che vedremo  ora:
\bb\begin{defin}{}{}
Prendiamo un sistema LTI generico:
\begin{equation*}
	\begin{dcases}
		\dot x(t) = Ax(t)+Bu(t) \\
		y(t) = Cx(t)+Du(t)
	\end{dcases} \quad x(0)=x_0 
\end{equation*}
Prendiamo la matrice $A$: siano $\lambda_1,\ldots, \lambda_r$, con $r \leq n$ autovalori reali o complessi coniugati ad essa associata, aventi molteplicità algebrica $m_1, \ldots, m_r \geq 0$ tali che la loro somma dia $n$ (somma non deve superare l'ordine della matrice, come detto sopra).
Vale che \textbf{le  componenti dell'evoluzione libera dello stato o dell'uscita del sistema lineare sono combinazioni lineari dei modi naturali}, ossia di funzioni del tipo:
\begin{equation}
	\boxed{t^{q-1}e^{\lambda_i t}} \quad \lambda_i \in \R \ oppure \ \mathbb{C} \ i.e. \ \lambda_i = \sigma_i + j\omega_i
\end{equation} Inoltre, \textbf{poiché l'uscita è lineare nello stato, anche l'evoluzione libera dell'uscita è esprimibile come combinazione lineare di modi naturali.} Potrebbero successivamente aggiungersi formule per l'approssimazione dell'evoluzione \textit{forzata}.
\end{defin}

\begin{prop}
	Se la matrice $A$ è reale e ammette un autovalore \textbf{complesso} $\lambda_i = \sigma_i + j\omega_i$, allora \textbf{anche il suo coniugato $\bar \lambda_i = \sigma_i - j\omega_i$ è autovalore di $A$}. Si dimostra inoltre che anche i coefficienti $\gamma_{jiq}$ associati a $\lambda, \bar \lambda$ sono a loro volta complessi coniugati.
\end{prop}
Nell'equazione della risposta forzata, i termini complessi coniugati sommati fra loro daranno luogo \textbf{a termini reali} del tipo $e^{\sigma_i t}\cos(\omega_i t+\phi_i)$, con opportuni valori di fase.
Ricordiamo infatti che:
\begin{equation*}
	e^{\lambda_i t} = e^{\sigma_i t}e^{j\omega_i t} = e^{\sigma_i t} \paren{\cos(\omega_i t ) + j\sin(\omega_i t)}
\end{equation*}

\subsection{Tipologie di modi naturali}
L'equazione dei modi naturali dipende dalla tipologia degli autovalori della matrice $A$:
\bb
$m.a. > m.g \rightarrow \left\{
\begin{tabular}{p{.7\textwidth}}
\begin{itemize}
	\item \textbf{reali} \rarr $\ t^{q-1}e^{\lambda_i t}$
	\item \textbf{complessi coniugati} \rarr $ \ t^{q-1}e^{\sigma_it}\cos(\omega_i t + \phi_i)$
\end{itemize}
\end{tabular}
\right.$
\bb
$m.a. = m.g \rightarrow \left\{
\begin{tabular}{p{.7\textwidth}}
\begin{itemize}
	\item \textbf{reali} \rarr $e^{\lambda_i t}$
	\item \textbf{complessi coniugati} \rarr $ \ e^{\sigma_i t}\cos(\omega_i t + \phi_i)$
\end{itemize}
\end{tabular}
\right.$ 
\bb
Notiamo da questa scrittura che \textbf{le uniche componenti capaci di modificare il comportamento dei modi in modo significativo sono sempre e solo entità reali.} In particolare, sarà interessante vedere cosa succede al variare di $\lambda_i$ nel caso di autovalori reali (sia semplici che non), e al variare di $\sigma_i$ nel caso di autovalori complessi coniugati (ancora, sia semplici che non).
\resource{0.4}{modi_nat_semplici}{\centering Variazione della traiettoria del modo in caso di autovalori \textbf{semplici} $(m.a. = m.g.)$, \\ dunque a sinistra $e^{\lambda_i t}$ e a destra $e^{\sigma_i t} \cos (\omega_i t + \phi_i)$.}

\resource{0.4}{modi_nat_nonsemp}{\centering Traiettoria del modo in caso di autovalori \textbf{non semplici} $(m.a. > m.g.)$, \\
dunque a sinistra $t^{q-1}e^{\lambda_i t}$ e a destra $t^{q-1}e^{\sigma_i t}\cos(\omega_i t + \phi_i)$.}

\bb
Si ha \textbf{convergenza del modo, e quindi dell'evoluzione libera, quando la parte reale dell'autovalore è negativa}. Il comportamento in caso di autovalore nullo è l'unico che varia: se l'autovalore è semplice, il sistema appare stabile (perché l'evoluzione è costante), ma resta una condizione da evitare. In caso di non semplicità, autovalori nulli non sono più considerabili validi, in quanto il termine polinomiale li rende divergenti. Ricordiamo: la divergenza indica eventuale \textit{rottura del sistema!} 
\bb
Graficando gli autovalori su un piano di Gauss, abbiamo che: a sinistra dell'asse immaginario, si hanno modi convergenti; a destra modi divergenti, a prescindere dalle considerazioni sulle molteplicità. Ciascun autovalore complesso ha anche il suo coniugato disegnato mediante simmetria rispetto all'asse reale. Cambia il comportamento sull'asse immaginario (quindi per autovalori a parte reale nulla): nel caso di autovalori semplici, si hanno modi costanti; nell'altro caso, divergenza.

\subsection{Stabilità di un sistema}
\begin{prop}
Abbiamo visto nella Proposizione \eqref{prop:sl_coppia_nulla_eq} che per un sistema \textbf{lineare} forzato la coppia $(0,0)$ è sempre di equilibrio. Per un non forzato, basta che sia $x_e = 0$ (in quanto $u_e = 0$ per definizione di non forzatura).
\end{prop}
\begin{prop}
	Si dimostra che nei i sistemi lineari \textbf{le proprietà di stabilità valgono per tutti gli equilibri e le traiettorie} del sistema. Di conseguenza, \textbf{studiare la stabilità in un punto equivale a studiarla in tutti gli altri.} Con questo concetto si definisce la \textbf{stabilità di un sistema.}
\end{prop}
\begin{proof}
	Supponiamo che $x_e$ sia un punto di equilibrio per il sistema LTI non forzato $\dot x(t) = Ax(t).$ Dalla definizione di equilibrio, allora, $f(x_e) = Ax_e = 0$. Studiamo ora il sistema in un generico punto $\tilde x(t)$, definito come la traiettoria calcolata al tempo $t$ rispetto ad $x_e$ (e non rispetto allo zero): 
\begin{equation*}
		\tilde x(t) = x(t) - x_e.
	\end{equation*}
	Sostituendo nell'equazione del sistema, abbiamo:
\begin{align*}
	\dv{t}(\tilde x(t)) = \dv{t}(x(t)-x_e) \longrightarrow \dot x(t) = Ax(t) & =A(\tilde x(t) + x_e)  = A\tilde x(t)+ \cancel{Ax_e} \\ & = A\tilde x(t),
	\end{align*}
	da cui il legame tra stato e un qualsiasi punto $\tilde x(t)$:
\begin{equation*}
	\dot x(t) = Ax(t) = A \tilde x(t) \longrightarrow x(t) = \tilde x(t).
\end{equation*}
\end{proof}
\begin{prop}
Preso un LTI, vale che se $$\ker (A) = \{ x \in \mathbb{K}^n \ : \ Ax = 0 \}= 0 \quad \rightarrow \quad x=0 \quad \textrm{è l'unico punto di equilibrio}$$ con $\mathbb{K}$ il campo degli elementi della matrice $A$. Questo è visibile dal fatto che la definizione del kernel non è altro che la funzione $f$ di un sistema LTI non forzato. Essendo un sottospazio vettoriale, il nullo è sempre un vettore dell'insieme (in questo caso, l'unico).\end{prop}

L'idea è quindi quella di \textbf{studiare l'origine} di un LTI, in quanto abbiamo visto essere sempre un punto di equilibrio: se questo è instabile, allora lo saranno tutti gli altri per cui si parla di \textbf{sistema instabile}. Questo è potentissimo: generalizzo un concetto studiando solo un caso particolare.
\begin{defin}{Teorema di Ljapunov}{}
	Consideriamo un sistema LTI (non c'è dipendenza dal tempo delle matrici). Questo è:
	\begin{itemize}
		\item \textbf{asintoticamente stabile} $\leftrightarrow$ \textbf{tutti gli autovalori della matrice $A$ hanno parte reale (strettamente) negativa.} In questo modo, infatti, lo stato sarà combinazione lineare di modi naturali convergenti. in simboli: \boxed{\forall \lambda_i, \ \ \Re{\lambda_i} < 0}
		\item semplicemente \textbf{stabile} $\leftrightarrow$ \textbf{tutti gli autovalori hanno parte reale minore o uguale a zero, ma gli autovalori a parte reale nulla sono necessariamente semplici}. Se questo non valesse avrei il termine polinomiale $t^{q-1}$ che  genererebbe un comportamento divergente. In simboli: \boxed{\forall \lambda_i \ : \ \Re{\lambda_i}= 0 \ \textrm{deve valere} \ m.a.(\lambda_i) = m.g.(\lambda_i)} 
	\end{itemize}
\end{defin}

\subsection{Retroazione statica dallo stato}
Cominciamo ad entrare nel vivo della materia. Quanto visto a livello puramente matematico è utilizzabile nella pratica per controllare un sistema dinamico (ad esempio, renderlo asintoticamente stabile se non lo è). Vediamo meglio. Un motore elettrico è un immediato esempio di sistema LTI.
\bb
Prendiamo l'equazione di stato un sistema LTI forzato:
 $$\dot x(t) = Ax(t) + Bu(t),$$ e supponiamo di avere $x_e$ come suo punto di equilibrio.  \textbf{Come usare l'ingresso $u(t)$ per rendere il sistema asintoticamente stabile, se $x_e$ non lo è già?} \textbf{È possibile usarlo anche per migliorarne  le prestazioni?} Queste domande sono tipiche del processo di \textit{sintesi di sistemi di controllo.} 
 \begin{lemma}
 	Idealmente, quando un sistema si discosta da un punto di equilibrio, si vuole fare in modo che questo \textit{ritorni ad esso in un tempo} al limite infinito, o che si muova verso \textit{un altro equilibrio}.
 \end{lemma}
\bb
Adesso facciamo un'importante considerazione: \textbf{supponiamo di conoscere, istante per istante, l'intero stato $x(t)$ del sistema.} Avremmo quindi collegato un sensore \textit{a ciascuna componente di $x(t)$:}
\begin{equation}
	y \in \R^n \ \longrightarrow \ y(t) = x(t) 
\end{equation}
Se il sistema non è attualmente stabile, sappiamo che è possibile lavorare al punto di equilibrio $x_e = 0$ e poi estendere quanto calcolato a tutto il sistema. Quando avremo $x_e$ stabile, allora avremo reso stabile \textit{l'intero sistema}. Come fare? Possiamo usare una \textbf{retroazione (statica) dallo stato}, in base alla quale si prende come $u(t)$ non una semplice funzione del tempo, ma una \textbf{funzione dell'intero stato $x(t)$} (o dell'uscita, visto che l'abbiamo direttamente collegata allo stato), a cui sommiamo eventualmente un ulteriore ingresso $v$:
\begin{equation}
	u(t) = K(x(t)) + v(t), \quad K : \R^n \rightarrow \R^m
\end{equation}
Il termine \textbf{statica} della retroazione deriva dal fatto che \textbf{u(t) dipende solamente dallo stato presente, ossia quello rilevato dai sensori al tempo $t$, i.e. $x(t)$.} Versione più evolute della retroazione prevedono dipendenze anche dallo stato passato. Non è questo il caso. La mappa $K$ va dalla dimensione dello stato alla dimensione degli ingressi del sistema ($m$, nel caso generale).
\bb
Attenzione, però: stiamo parlando di sistemi LTI, per cui la mappa $K$ può essere senz'altro presa \textbf{lineare}, per cui scrivibile, per quanto visto nelle pagine precedenti, come \textbf{combinazione lineare} di elementi di $x(t)$. Questo si traduce in una scrittura in forma matriciale:
\begin{equation}
	u(t) = Kx(t) + v(t), \quad K \in \mathcal{M}(m,n,\R).
\end{equation}
Riprendiamo ora la dinamica, e applichiamo l'ingresso appena descritto:
\begin{align}
	\dot x(t) & = Ax(t) + B\paren{Kx(t) + v(t)} = Ax(t) + BKx(t) + Bv(t) \nonumber \\ & = \boxed{\mathbf{(A+BK)}x(t) + Bv(t)}
\end{align}
Abbiamo un sistema detto \textbf{in anello chiuso} (in quanto prende l'intero stato e lo riporta, eventualmente con un'ingresso aggiunto $v(t)$, in ingresso), che non è più forzato; visto che è LTI, \textbf{posso studiare le componenti spettrali della matrice $A+BK$ per caratterizzare il sistema.} La domanda è \textbf{come scegliere la matrice $K$ in modo che il sistema sia asintoticamente stabile?} È evidente che ciò si raggiunge facendo in modo che $A+BK$ abbia \textbf{tutti gli autovalori a parte reale negativa.}
\bb
\begin{defin}{Scelta di $K$ (\textit{pole placement}) e raggiungibilità di un sistema}{}
Vale, ma non è provato qui, che se il sistema descritto dall'equazione di stato $\dot x(t)=Ax(t)+Bu(t)$ è \textbf{raggiungibile}, posso \textbf{allocare arbitrariamente tutti gli autovalori} di $A+BK$, sia in termini di valore che di posizione. Più questi saranno a parte reale negativa, più convergenti saranno i modi che descriveranno la traiettoria del sistema (perfetto!).
\bb
Diciamo che la proprietà di \textit{raggiungibilità}, insieme a quella di \textit{controllabilità} descrivono le possibilità di azione dell'ingresso $u(\cdot)$ al fine di \textit{influenzare la traiettoria di stato.}	
\end{defin}
L'obiettivo è quello di prendere un ingresso \textit{proporzionale all'errore che lo stato ha rispetto all'equilibrio} che si vuole raggiungere. Tutto questo però funziona a patto che sia soddisfatta un'\textbf{ipotesi estremamente forte: siamo capaci di misurare, istante per istante, l'intero stato $x(t)$ del sistema.} Cosa succede se questo non può accadere? Consideriamo due strade percorribili:
\begin{itemize}
	\item \textbf{teoria dei sistemi} \rarr continuare a lavorare nello spazio di stato e ricostruire $x(t)$ da $y(t)$. La copia creata si chiama \textbf{stima dello stato $\bar x(T)$}, e sarà poi utilizzabile nell'equazione dell'ingresso, che diventerà $u(t) = K\bar x(t)$. Per la ricostruzione entrano in gioco sistemi ausiliari di stima chiamati \textbf{osservatori} (il cui funzionamento dipenderà \textit{dall'osservabilità} del sistema in studio). Questo approccio non verrà utilizzato qui;
	\item \textbf{studio di sistemi LTI SISO} \rarr vedremo che in questo caso $(m = p = 1)$, lo stato sarà analizzabile lavorando nel \textbf{dominio di Laplace}.
\end{itemize}

\section{Linearizzazione di sistemi non lineari tempo invarianti (NLTI)}
L'idea alla base della linearizzazione è quella di non dover buttare via tutti i risultati utilissimi visti per l'analisi (e la sintesi) di sistemi LTI (modi, retroazione, stabilità globale mediante studio puntuale...), ma di utilizzarli anche per i NLTI.
\bb
	Supponiamo di avere un sistema non lineare tempo invariante$$\begin{dcases}
	\dot x(t) = f(x(t),u(t)) \\
	y(t) = h(x(t), u(t))
\end{dcases}
 \quad \quad x(0) = x_0$$
	Supponiamo $(x_e,u_e)$ siano una coppia di equilibrio. Allora sappiamo che $f(x_e, u_e) = 0$. Consideriamo ora una traiettoria di stato a partire dallo stato iniziale $x(0) = x_e + \Delta x_0$, e una traiettoria di uscita:
\begin{align*}
\underbrace{x(t) = x_e+\Delta x(t), \quad \quad u(t) = u_e+ \Delta u(t)}_{\textrm{traj. di stato } (x(t), u(t))}, \quad  \quad \underbrace{y(t) = h(x_e, u_e) + \Delta y(t) = y_e + \Delta y(t)}_{\textrm{traj. di uscita}}
\end{align*}
Stiamo cioè considerando traiettorie che non partono più dall'equilibrio, ma da un punto vicino ad esso. Essendo traiettorie, le funzioni di cui sopra risolveranno le equazioni, rispettivamente, di stato e uscita:
\begin{align*}
\begin{dcases}
	\dv{t}(x_e + \Delta x(t)) = f\paren{x_e+\Delta x(t), u_e + \Delta u(t)} \\
	y_e + \Delta y(t) = h(x_e+\Delta x(t), u_e + \Delta u(t))
\end{dcases} = (\star)
\end{align*}
\newpage
Sviluppiamo ora $f$ e $h$ con Taylor per funzioni a due variabili\footnote{Sia $f: A \subseteq \R^2 \rightarrow \R$. Fissato un punto $(x_0, y_0) \in A$, definiamo lo sviluppo in serie Taylor con questo polinomio:
\begin{align*}
	T(x,y) & = f(x_0, y_0) + \pdv{f(x_0, y_0)}{x} (x - x_0)+\pdv{f(x_0, y_0)}{y} (y - y_0) +\\ & + \frac{1}{2} \sparen{\pdv[2]{f(x_0, y_0)}{x} (x - x_0)^2 + \pdv[2]{f(x_0, y_0)}{y} (y - y_0)^2 + \pdv{f(x_0, y_0)}{x}{y} (x - x_0)(y-y_0)} + \textrm{termini ordine sup.}
\end{align*}
}, nel punto $(x_0, u_0) = (x_e, u_e)$, fermandoci alle derivate parziali prime:
\begin{align*}
	f(x_e + \Delta x(t), u_e + \Delta u(t)) & \stackrel{T}{=} \cancel{f(x_e, u_e)} + \pdv{f(x_e, u_e)}{x} (x_e + \Delta x(t) - x_e)+\pdv{f(x_e, u_e)}{u} (u_e + \Delta u(t) - u_e) \\ & =  \pdv{f(x_e, u_e)}{x} \Delta x(t)+\pdv{f(x_e, u_e)}{u} \Delta u(t) + \textrm{termini ord. sup.}
\end{align*}
Analogamente per l'uscita (i passaggi sono soppressi):
\begin{align*}
h(x_e + \Delta x(t), u_e + \Delta u(t)) \stackrel{T}{=} h(x_e, u_e)+\pdv{h(x_e, u_e)}{x} \Delta x(t)+\pdv{h(x_e, u_e)}{u} \Delta u(t) + \textrm{termini ord. sup.}
\end{align*}
Perché ci siamo fermati al primo ordine del polinomio? Ricordiamo l'obiettivo: vogliamo ricondurre le equazioni di un sistema NLTI (che presentano quindi le generali $f,h$) ad equazioni di un sistema LTI. Dobbiamo mettere in conto che per far questo è necessario \textit{accettare un errore di approssimazione} che deriva proprio dal fermarsi prima. Riprendiamo le equazioni del NLTI, e sosituiamo al posto di $f,h$ i polinomi di Taylor che abbiamo appena calcolato:
\begin{align*}
	(\star) = \begin{dcases}
	\dv{t}(x_e + \Delta x(t)) = \pdv{f(x_e, u_e)}{x} \Delta x(t)+\pdv{f(x_e, u_e)}{u} \Delta u(t) \\
	y_e + \Delta y(t) = h(x_e, u_e) + \pdv{h(x_e, u_e)}{x} \Delta x(t)+\pdv{h(x_e, u_e)}{u} \Delta u(t)
\end{dcases} = (\star_2)
\end{align*}
Sviluppiamo la derivata al primo membro dell'equazione di stato, ottenendo $\dot{\Delta x(t)}$, e, sapendo che $y_e = h(x_e, u_e)$ dalla definizione di equilibrio, cancelliamo i termini dalla seconda equazione:
\begin{align*}
	(\star_2) = \begin{dcases}
	\dot{\Delta x(t)} = \pdv{f(x_e, u_e)}{x} \Delta x(t)+\pdv{f(x_e, u_e)}{u} \Delta u(t) \\
	\Delta y(t) = \pdv{h(x_e, u_e)}{x} \Delta x(t)+\pdv{h(x_e, u_e)}{u} \Delta u(t)
\end{dcases} 
\end{align*}
Quella che abbiamo appena scritto è la \textbf{forma di stato di un sistema lineare tempo invariante}! Le espressioni delle derivate parziali sono infatti delle matrici \textit{jacobiane}, ossia contenenti le derivate parziali fatte rispetto a ciascuna variabile di ciascuna componente della funzione specificata:
\begin{align*}
	\pdv{f(x_e, u_e)}{x} = \eval{\begin{bmatrix}
		\pdv{f_1(x, u)}{x_1} & \cdots	& \pdv{f_1(x, u)}{x_n} \\
		\vdots & \ddots & \vdots \\
	\pdv{f_n(x, u)}{x_1} & \cdots & \pdv{f_n(x, u)}{x_n}
	\end{bmatrix}}_{\substack{x=x_e \\ u=u_e}} 
	\quad 
	\pdv{f(x_e, u_e)}{u} = \eval{\begin{bmatrix}
	\pdv{f_1(x, u)}{u_1} & \cdots & 	\pdv{f_1(x, u)}{u_m} \\
		\vdots & \ddots & \vdots \\
	\pdv{f_n(x, u)}{u_1} & \cdots &		\pdv{f_n(x, u)}{u_m}
	\end{bmatrix}}_{\substack{x=x_e \\ u=u_e}} 
\end{align*}
\begin{align*}
	\pdv{h(x_e, u_e)}{x} = \eval{\begin{bmatrix}
		\pdv{h_1(x, u)}{x_1} & \cdots	& \pdv{h_1(x, u)}{x_n} \\
		\vdots & \ddots & \vdots \\
	\pdv{h_p(x, u)}{x_1} & \cdots & 		\pdv{h_p(x, u)}{x_n}
	\end{bmatrix}}_{\substack{x=x_e \\ u=u_e}}  \quad 
	\pdv{f(x_e, u_e)}{u} = \begin{bmatrix}
	\pdv{h_1(x, u)}{u_1} & \cdots & 	\pdv{h_1(x, u)}{u_m} \\
		\vdots & \ddots & \vdots \\
	\pdv{h_p(x, u)}{u_1} & \cdots &		\pdv{h_p(x, u)}{u_m}
	\end{bmatrix}_{\substack{x=x_e \\ u=u_e}} 
\end{align*}
Chiamiamo queste matrici $A_e, B_e, C_e, D_e$, e riscriviamo la dinamica (usando il simbolo di approssimazione perché ricordiamo di aver tolto i termini di ordine superiore dallo sviluppo di Taylor, cosa che inevitabilemnte va a generare un'imprecisione):
\begin{align*}
	\begin{dcases}
		\dot{\Delta x(t)} \approx A_e \Delta x(t) + B_e \Delta u(t) \\
		\Delta y(t) \approx C_e \Delta x(t) + D_e \Delta u(t) 
	\end{dcases}, \quad \Delta x(0) = \Delta x_0
\end{align*}
\newpage
A questo punto, possiamo dare il risultato finale:
\begin{defin}{Linearizzazione di un sistema NLTI nell'intorno ad un equilibrio}{}{}
	Dato un sistema non lineare tempo invariante avente la seguente forma di stato:
\begin{equation*}
	\begin{dcases}
	\dot x(t) = f(x(t),u(t)) \\
	y(t) = h(x(t), u(t))
\end{dcases}
 \quad \quad x(0) = x_0
	\end{equation*}
	Mediante approssimazioni al primo ordine sulle funzioni $f,h$, è possibile \textbf{linearizzarlo nell'intorno di una coppia di equilibrio $(x_e, u_e)$}, in modo che diventi scrivibile in forma matriciale esattamente come un sistema LTI (la $\delta$ è solo \textit{notazione}):
\begin{equation}
\label{eq:lti_da_nlti}
	\begin{dcases}
		\dot{\delta x(t)} = A_e \delta x(t) + B_e \delta u(t) \\
		\delta y(t) = C_e \delta x(t) + D_e \delta u(t)
	\end{dcases}
	\end{equation}
	con $A_e,\cdots, D_e$ matrici \textit{jacobiane} la cui forma è scritta sopra. 
	Vale che:
	\begin{equation}
		(\delta x(t), \delta u(t)), \ t \geq 0
	\end{equation}
	è una \textbf{traiettoria del sistema LTI} descritto alla \eqref{eq:lti_da_nlti}, e si vuole che questa approssimi le variazioni di stato e l'uscita del NLTI con qualcosa che è $x_e$ (o $u_e$) più una componente lineare di \textit{perturbazione} $\delta x(t)$ (o $\delta u(t)$):
\begin{equation}
		x(t) \approx x_e + \delta x(t), \quad \quad u(t) \approx u_e + \delta u(t)
	\end{equation}
	Di conseguenza, è necessario che le variazioni del sistema non lineare rispetto al punto di equilibrio (dove abbiamo linearizzato) siano sufficientemente piccole, in modo da riuscire a \textit{confonderle}. 
	\end{defin}
	
\subsection{Retroazione dallo stato applicata a sistemi NLTI}
Quanto visto nella sezione sulla retroazione dallo stato per sistemi LTI non asintoticamente stabili può essere applicato ad un qualunque sistema NLTI linearizzabile, semplicemente \textbf{agendo sulla sua linearizzazione}. Consideriamo un NLTI e linearizziamolo nell'intorno dell'equilibrio $(x_e, u_e)$:
\begin{equation*}
	\dot x(t) = f(x(t), u(t)) \quad \rightsquigarrow \quad \dot{\delta x(t)} = A_e \delta x(t) +B_e \delta u(t)
\end{equation*}
Possiamo dunque dire che, nelle vicinanze di $(x_e, u_e)$ l'NLTI si approssima al primo ordine con l'LTI di destra. Le matrici $A_e, B_e$ sono le jacobiane calcolate all'equilibrio che abbiamo visto qualche pagina fa. Prendiamo ora il caso che questo LTI non sia stabile; per renderlo stabile (e sappiamo che se lo facciamo in corrispondenza di un punto di equilibrio, varrà per tutti gli altri) possiamo sfruttare il \textit{pole placement} mettendo in gioco la matrice $K$ con l'obiettivo di \textbf{portare $x(t)$ ad $x_e$ in modo approssimato}, i.e. di annullare la perturbazione $\delta x(t)$. Supponendo ancora una volta di \textbf{essere in grado di conoscere l'intero stato istante per istante}, è possibile utilizzare un ingresso del tipo:
\begin{equation}
	\delta u(t) = K\delta x(t) + \delta v(t), \quad K \in \mathcal{M}(m,n,\R).
\end{equation}
Il sistema in anello chiuso sarà dunque descritto da:
\begin{equation}
	\dot{\delta x(t)} = (\mathbf{A_e + B_e K})\delta x(t) + B_e \delta v(t)
\end{equation}
A questo punto, supponendo raggiungibilità, è possibile allocare gli autovalori che mi interessano con l'obiettivo di rendere la matrice in grassetto asintoticamente stabile (che si traduce in componenti spettrali aventi parte reale negativa).
\begin{prop}
	Se il sistema linearizzato nell'intorno di $(x_e, u_e)$ associato al NLTI è asintoticamente stabile, allora il non lineare \textbf{convergerà ad $x_e$}, e quindi sarà \textbf{localmente stabile} in quel punto, \textbf{se parte da un intorno sufficientemente piccolo da $x_e$} stesso.
\end{prop} 
In altre parole, linearizzare un pendolo nell'intorno di un equilibrio $(\pi, 0)$ e renderlo asintoticamente stabile lì, non renderà il NLTI associato stabile, se quest'ultimo parte da $(0,0)$, perché siamo ben fuori dall'intorno in cui la linearizzazione ha validità.
\newpage
Vediamo infine come riportare al sistema NLTI l'\textbf{equazione dell'ingresso con feedback} che prima abbiamo definito per il linearizzato. In particolare, sapendo che $u(t) \approx u_e + \delta u(t)$ e che $x(t) \approx x_e + \delta x(t)$, scriviamo:
\begin{align}
	u(t) = u_e + (K\delta x(t) + \delta v(t)) = u_e + K(x(t) - x_e) + \delta v(t),
\end{align}
con $K$ progettata sul sistema linearizzato.
\resource{0.5}{linearizz}{Schema di un NLTI reso localmente stabile mediante feedback dallo stato e linearizzazione.}
\bb
\begin{prop}
	Se la linearizzazione di un NLTI ha una matrice $A$ avente almeno una componente spettrale a parte reale positiva (o nulla e non semplice), allora non è stabile in quel punto e non lo sarà nemmeno (localmente) il non lineare associato.
\end{prop}

\section{Esempio e note aggiuntive}

\begin{esem}
	Vediamo ora un esempio di linearizzazione e stabilizzazione di un sistema NLTI. Ricordiamo l'equazione di stato del pendolo:
	\begin{equation*}
		\dot x(t) = \begin{bmatrix}
			\dot x_1(t) \\ \dot x_2 (t)
	\end{bmatrix} = \begin{bmatrix}
		x_2(t)\\
		-\frac{g}{l} \sin(x_1(t)) - \frac{b}{Ml^2} x_2(t) + \frac{1}{Ml^2}u(t)
	\end{bmatrix}
	\end{equation*}
	Consideriamo un equilibrio per questo sistema, della forma $\begin{pmatrix}\begin{pmatrix}
		x_{1e} \\ x_{2e}
	\end{pmatrix}, u_e
	\end{pmatrix}$. Vale che un punto di eq. annulla la funzione $f$, per cui scriviamo:
	\begin{equation*}
	\begin{bmatrix}
		x_{2e}\\
		-\frac{g}{l} \sin(x_{1e}) - \frac{b}{Ml^2} x_{2e} + \frac{1}{Ml^2}u_e
	\end{bmatrix} = \begin{bmatrix}
		0 \\ 0 
	\end{bmatrix} \Rightarrow \begin{dcases}
	u_e = - Mlg \sin(x_{1e})\\
		x_{2e} = 0
	\end{dcases}
	\end{equation*}
	Uno stato di equilibrio per il pendolo comporta quindi sempre $x_{2e} = 0$, che rappresenta la velocità angolare. Questo ha senso! La coppia in questione è quindi:
	\begin{equation*}
	\begin{pmatrix}
	\begin{pmatrix}
			x_{1e} \\ 0
	\end{pmatrix}, -Mlg\sin(x_{1e})
	\end{pmatrix}
	\end{equation*}
	Esempi di equilibrio sono la posizione verticale in basso $(x_e = \mathbf{0}_{\R^2})$ oppure verticale $(x_{1e} = \pi)$. In entrambi i casi si ha $u_e = 0$, il che significa che non è necessario applicare un ingresso per mantenerlo in equilibrio (ed è effettivamente sensato). In una qualsiasi altra posizione, l'effetto di $g$ doveva essere controbilanciato da una $u(t)$, per mantenere lo stato costante (alrimenti cadrebbe).
Linearizziamo ora il NLTI intorno a questo equilibrio. Otteniamo la scrittura
\begin{align*}
	\dot{\delta x(t)} = A_e \delta x(t) + B_e \delta u(t) & = \eval{\begin{bmatrix}
		\pdv{f_1(x, u)}{x_1} & \pdv{f_1(x, u)}{x_2} \\
		\pdv{f_2(x, u)}{x_1} & \pdv{f_2(x, u)}{x_2}
	\end{bmatrix}}_{\substack{x=x_e \\ u=u_e}}  \delta x(t) + \eval{\begin{bmatrix}
		\pdv{f_1(x, u)}{u} \\ \pdv{f_2(x, u)}{u}
	\end{bmatrix}}_{\substack{x=x_e \\ u=u_e}}  \delta u(t) \\ & = \eval{\begin{bmatrix}
		0 & 1 \\ -\frac{g}{l} \cos(x_{1}(t)) & -\frac{b}{Ml^2} 
	\end{bmatrix}}_{\substack{x=x_e \\ u=u_e}}  \delta x(t) + \eval{\begin{bmatrix}
		0 \\ \frac{1}{Ml^2}
	\end{bmatrix}}_{\substack{x=x_e \\ u=u_e}} \delta u(t) \\ & = \begin{bmatrix}
		0 & 1 \\ -\frac{g}{l} \cos(x_{1e}) & -\frac{b}{Ml^2} 
	\end{bmatrix}  \delta x(t) + \begin{bmatrix}
		0 \\ \frac{1}{Ml^2}
	\end{bmatrix} \delta u(t) 
\end{align*}
Analizziamo la stabilità di questo sistema lineare (che approssima al primo ordine il non lineare di partenza, nell'intorno di un punto di equilibrio), e nel caso procediamo con il pole placement. Consideriamo due casi di equilibrio:
\subsubsection{Caso $((x_{1e}, x_{2e}), u_e) = ((0,0), 0)$}
Il linearizzato intorno a questo punto ha la forma:
\begin{align*}
	\dot{\delta x(t)} = \begin{bmatrix}
 0 & 1 \\ -\frac{g}{l} & - \frac{b}{Ml^2}	
 \end{bmatrix} \delta x(t) + \begin{bmatrix}
 	0 \\ \frac{1}{Ml^2}
 \end{bmatrix} \delta u(t) \quad \rightarrow \quad 
	\det(A_e - \lambda I) = 0 \rightarrow \cdots \rightarrow \ \Re{\lambda_i} < 0 \ \forall i
\end{align*}
Avendo componenti spettrali tutte a parte reale negativa, il sistema LTI è asintoticamente stabile. Questo si traduce in stabilità \textbf{locale} per il NLTI, per variazioni di posizione dal punto di equilibrio sufficientemente piccole.

\subsubsection{Caso $((x_{1e}, x_{2e}), u_e) = ((\pi,0), 0)$}
\begin{align*}
	\dot{\delta x(t)} = \begin{bmatrix}
 0 & 1 \\ \frac{g}{l} & - \frac{b}{Ml^2}	
 \end{bmatrix} \delta x(t) + \begin{bmatrix}
 	0 \\ \frac{1}{Ml^2}
 \end{bmatrix} \delta u(t) \quad \rightarrow \quad 
	\det(A_e - \lambda I) = 0 \rightarrow \cdots \rightarrow \ \exists \lambda_i \ : \ \Re{\lambda_i} > 0
\end{align*}
per cui LTI \textbf{non è} asintoticamente stabile, e occorre passare al pole placement (matrice $K$). Non faremo mai questo calcolo a mano, ma utilizzeremo sempre MATLAB:

\begin{lstlisting}[
  style = Matlab-editor,
  basicstyle = \mlttfamily]
  % [ ... ]
  K = place(A_e, B_e, [-0.5; -0.6]);
  K = -K; % Matlab calcola K considerando A-BK, noi vogliamo A+BK
  
  input = @(t,x) K*(x-x_e);
  
  dyn = @(t, x) [x(2); -g/l*sin(x(1)) - b/(m*l^2)*x(2) + inp(t,x)/(m*l^2)];
  [time, traj] = ode45(dyn, interv, x0);
\end{lstlisting}
Dunque ML calcola, mediante la funzione \texttt{place} una matrice di feedback dallo stato $K$ tale che gli \textbf{autovalori di $A-BK$ siano quelli specificati nel vettore passato come terzo parametro della funzione}. A questo punto, bisogna effettivamente applicare il feedback considerando un input $$u(t) = K(x(t)) \ \textrm{che nel nostro caso diventa} \ \boxed{u(t) =K(\delta x(t)) = K(x(t) - x_e)}$$
Possiamo verificare che effettivamente gli autovalori di $A+BK$ siano quelli scelti da noi mediante la funzione \texttt{eig(A+BK)}. È importante, quindi, l'istruzione \texttt{K = -K}! La simulazione darà un esito di stabilità a patto che il NLTI parta da un punto sufficientemente vicino all'equilibrio che abbiamo utilizzato per la linearizzazione (e il pole placement). Se questo non accade, il sistema NLTI \textbf{non} sarà stabile!

\subsubsection{Caso extra in cui $b = 0$ e punto di equilibrio generico $((x_{1e},x_{2e}),u_e)$}
Il nostro linearizzato sarà:
\begin{equation*}
	\dot{\delta x(t)} = \begin{bmatrix}
 0 & 1 \\ -\frac{g}{l}\cos(x_{1e}) & 0	
 \end{bmatrix} \delta x(t) + \begin{bmatrix}
 	0 \\ \frac{1}{Ml^2}
 \end{bmatrix} \delta u(t) \quad \rightarrow \quad 
	\det(A_e - \lambda I) = 0 \rightarrow \ \lambda = \pm j \sqrt{\frac{g}{l}  \cos(x_{1e})} 
\end{equation*}
Notiamo che nei due equilibri considerati sopra si ha una situazione di \textbf{stabiità marginale} dell'LTI, in quanto gli autovalori sono \textbf{semplici e a parte reale nulla} (ricordiamo: questo è ancora un caso valido, visto che ho supposto la semplicità!). Non appena insorge una perturbazione (cosa perfettamente plausibile, visto che la linearizzazione approssim soltanto il NLTI) si ha divergenza, e il sistema di fatto oscillerà all'infinito senza mai fermarsi. 
\end{esem}

\subsection{Controllo ottimo}
Non abbiamo per niente considerato, in queste pagine, quali performance otteniamo quando applichiamo un particolare tipo di controllo automatico ad un sistema dinamico, e nemmeno il costo dell'implementazione. Progettare per il raggiungimento di certi obiettivi operando certe misure di controllo di costo (che non è necessariamente economico) va sotto il nome di \textbf{controllo ottimo}, che in questo corso non verrà affrontato in generale.

\input{laplace_domain.tex}

\end{document}





