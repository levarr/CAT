% !TEX root = ./main.tex

\part{Analisi nel dominio di Laplace}

\chapter{Laplace $\mathcal{L}\sparen{\cdot}$}
Come già visto in altri ambiti con Steinmetz e Fourier, anche in questo corso può rivelarsi utile spostare un problema dal dominio temporale ad un altro, risolverlo lì, e riportare la soluzione di nuovo nel tempo.
\resource{0.5}{laplace}{Risoluzione nel dominio di Laplace}
I concetti che vedremo faranno forte uso dei numeri complessi, che però \textbf{non} verranno ripresi qui perché sono sempre le solite cose (rappresentazione cartesiana, polare, esponenziale, come passare dall'una all'altra, proprietà varie). Rimando alla dispensa di TLC-1 dove queste cose sono trattate di più.
\section{Trasformata}
\begin{defin}{}{}
Sia $f: \R \rightarrow \C$ (in questo corso tipicamente $f: \R \rightarrow \R$); sia $s = \sigma + j\omega \in \C$. Definiamo la \textbf{trasformata di Laplace} (se esiste) come:
\begin{equation}
	\lt{f(t)} = F(s) = \ltint{f(t)}{-st}{t}
\end{equation} 
Ci muoviamo, quindi, dal dominio del tempo, al \textbf{dominio di Laplace}: $f(t) \xrightarrow{\Lap} F(s)$. Notiamo gli estremi di integrazione: Laplace non è definita, come Fourier, su tutto l'asse reale, ma solo sul \textbf{semiasse positivo} $[0^-, \pinf]$. Lo $0^-$ è incluso perché bisogna tenere conto, in fase di trasformazione, di eventuali \textbf{impulsi in $t = 0$ della $f$}. La funzione integranda è complesso, per cui l'integrale stesso (e dunque $F(s)$) è complesso. \bb Dato il dominio di definizione, si può dire che l'operazione di trasformazione \textbf{non è biunivoca}, i.e. non è vero che ad ogni $f$ corrisponde una e una sola $F$. Potrei prendere delle funzioni del tutto diverse tra loro nell'intervallo $\R^-$, ma poi identiche in $\R^+$: queste avranno la stessa trasformata. Per ottenere biunivocità, considereremo  sempre \textbf{funzioni definite nel semiasse positivo di $\R$, e nulle altrove} (dette \textbf{funzioni causali)}:
\begin{equation}
	f(t) = 0 \quad \forall t < 0^-
\end{equation}
Supponendo di lavorare con sistemi \textit{tempo invarianti}, questa restrizione non comporta perdità di generalità: posso traslare una qualsiasi funzione TI di un certo valore temporale $t_0$ per riportarla completamente nel dominio $[0^-, \pinf]$, e si comporterà identicamente a come si comporterebbe se non fosse traslata. 
\end{defin}

\begin{prop}
Si può far vedere che:
\begin{equation}
	\exists \bar \sigma \ : \ \forall s = \sigma + j \omega \ \textrm{avente} \ \sigma > \bar \sigma \ \longrightarrow \ F(s) = \int \cdots \dd{t} \ \textrm{converge}.
\end{equation}
Esiste cioè un'ascissa $\bar \sigma$ sul piano complesso, detta \textbf{di convergenza}, a destra della quale si trovano tutti i complessi che fanno \textbf{convergere l'integrale} della trasformazione di Laplace. Dunque, \textbf{la trasformata esiste a destra di quest'ascissa} (i.e. nel semipiano $\Re{s} > \bar \sigma$), (ma sarà possibile estendere l'esistenza anche a sinistra di $\bar \sigma$, i.e. per $\Re{s} \leq \bar \sigma$).
\end{prop}

\subsection{Trasformata come rapporto di polinomi}
Vedremo nel corso $f(t)$ aventi sempre come trasformata un \textbf{rapporto di polinomi} (a coefficienti reali, se $f$ è reale):
\begin{equation}
\label{lt_rap}
	F(s) = \frac{N(s)}{D(s)}
\end{equation} 
Le radici del numeratore ($N(s) = 0$) sono dette \textbf{zeri}, quelle del denominatore, \textbf{poli}. Valgono i seguenti:
\begin{them}
(del valore iniziale). Se $f(t)$ è una funzione reale avente trasformata $F(s)$ esprimibile come in \eqref{lt_rap}, e \textbf{il grado di $D(s)$ è maggiore di quello di $N(s)$}, allora
\begin{equation}
\llimit{s}{\pinf}{sF(s)} = f(0).
\end{equation}
\end{them}

\begin{them} (del valore finale). Se alle ipotesi del teorema di cui sopra aggiungiamo anche che \textbf{il denominatore ha tutti i poli nulli o a parte reale negativa}, allora vale
\begin{equation}
\llimit{s}{0}{sF(s)} = \llimit{t}{\pinf}{f(t)}
\end{equation} 
\end{them}
Grazie a questi possiamo determinare i \textbf{valori asintotici }iniziali e finali di una funzione nel tempo \textbf{partendo dalla sua trasformata} di Laplace. Le dimostrazioni sono omesse.

\section{Antitrasformata}
\begin{defin}{}{}
Per tornare nel dominio del tempo ($F(s) \xrightarrow{\Lap^{-1}} f(t)$) usiamo la formula di \textbf{antitrasformazione}:
\begin{equation}
	f(t) = \lat{F(s)} = \latint{F(s)}{st}{s}, \quad \quad \sigma > \bar \sigma.
\end{equation}
Notiamo la restrizione per $\sigma$: abbiamo detto che $F(s)$ esiste a destra di $\bar \sigma$, quindi l'antitrasformazione (che integra $F(s)$ stesso) dovrà rispettare questo requisito. Questa formula non verrà mai utilizzata praticamente.
\end{defin}


\section{Proprietà}
\begin{itemize}
	\item \textbf{Linearità} \rarr \boxed{\lt{\alpha f(t) + \beta g(t)} = \alpha \lt{f(t)} + \beta \lt{g(t)}, \ \forall \alpha, \beta \in \R} \\ \\ si dimostra sfruttando la linearità dell'operatore integrale;
	\item \textbf{Traslazione temporale} \rarr \boxed{\lt{f(t-\tau)} = \lt{f(t)}e^{-s\tau}, \ \forall \tau > 0} : \\ \\ la trasformata di una funzione traslata sarà la trasformata della funzione non traslata, più un termine moltiplicativo che dipende dal quantitativo di traslazione.
	\begin{proof}
	Usiamo la definizione e consideriamo un cambio di variabile $y = t-\tau$, da cui $\dd{y} = \dd{t}$:
	\begin{align*}
		\lt{f(t-\tau)} = F(s) & = \ltint{f(t-\tau)}{-st}{t} = \int_{-\tau}^{\pinf} f(y)e^{-s(y+\tau)} \dd{y} = (\star)
	\end{align*}
	ma abbiamo detto di voler considerare funzioni nulle nel semiasse negativo, per cui possiamo cambiare l'estremo di integrazione:
	\begin{equation*}
		(\star) = \int_{0^-}^{\pinf} f(y)e^{-sy}\dd{y} e^{-s\tau} = \lt{f(t)}e^{-s\tau}.
	\end{equation*}
	\end{proof}
	\item \textbf{Traslazione nel dominio complesso} \rarr \boxed{\lt{e^{\alpha t}f(t)} = F(s-\alpha), \ \forall \alpha \in \C} : \\ \\ la traslazione nel dominio di Laplace  di un certo complesso $\alpha$ corrisponde ad un termine moltiplicativo nel dominio del tempo che dipende dalla translazione;
	\begin{proof}
		\begin{equation*}
		\lt{e^{\alpha t}f(t)}  = \ltint{e^{\alpha t}f(t)}{-st}{t} = \ltint{f(t)}{-(s-\alpha)t}{t} = F(s-\alpha) 		
		\end{equation*}
	\end{proof}
	\item \textbf{Derivazione (nel tempo)} \rarr \boxed{\lt{\dv{f(t)}{t}} = sF(s)-f(0^-)}
		\begin{proof}
	Usiamo la definizione di trasformata e applichiamo l'integrazione per parti:
	\begin{align*}
		\lt{\dv{f(t)}{t}} & = \ltint{\dv{f(t)}{t}}{-st}{t}	 = \eval{f(t)e^{-st}}_{0^-}^{\pinf} - \int_{0^-}^{\pinf} f(t)(-s)e^{-st} \dd{t} \\ & = 0 - f(0^-) + \int_{0^-}^{\pinf} sf(t)e^{-st} \dd{t} = - f(0^-) + s \int_{0^-}^{\pinf} f(t)e^{-st} \dd{t} \\ & = - f(0^-) + s \lt{f(t)} = sF(s) - f(0^-).
	\end{align*}
	\end{proof}
	\item \textbf{Derivazione (nel tempo) generica} \rarr \boxed{\lt{\dv[n]{f(t)}{t}} = s^{n} F(s) - \sum_{i=1}^{n} s^{n-i} \eval{\dv[i-1]{f(t)}{t}}_{t=0^-}} \footnote{
	Verifichiamo che è valida per la derivata prima:
	\begin{equation*}
		\lt{\dv{f(t)}{t}} = s^1 F(s) - \sum_{i=1}^1 \cdots = s F(s) - s^{0} \eval{f(t)}_{0^-} = sF(s)-f(0^-).
	\end{equation*}}
	\item \textbf{Integrazione (nel tempo)} \rarr \boxed{\lt{\int_0^t f(\tau) \dd{\tau}} = \frac{F(s)}{s}}
\item \textbf{Convoluzione (nel tempo)} \rarr \boxed{\lt{f_1(t) \circledast f_2(t)} = \lt{\int_0^t f_1(t-\tau)f_2(\tau) \dd{\tau}} =  F_1(s)F_2(s)} : \\ \\ il \textbf{prodotto di convoluzione} è definito come l'integrale del prodotto tra una funzione ferma e una seconda che trasla sulla prima. NB: supponiamo che le funzioni $f_1,f_2$ siano nulle per $t < 0$. Nel dominio di Laplace, questo si trasforma in un prodotto semplice tra le trasformate.
\end{itemize}

\section{Trasformate di segnali elementari}
\begin{minipage}
{0.5\textwidth}
\resource{0.4}{lap_elem}{Segnali elementari (1)}
\end{minipage}
\begin{minipage}
{0.5\textwidth}
\resource{0.4}{lap_elem2}{Segnali elementari (2)}
\end{minipage}
\bb
\textbf{Osservazione:} è importante focalizzarci sul gradino di Heaviside $1(t)$, perché è quella funzione che, moltiplicata per una qualsiasi altra $f(t)$, la rende \textbf{causale}, i.e. nulla per $t < 0$ e inalterata per $t \geq 0$. Poiché, come già detto, vogliamo avere a che fare solo con robe di questo tipo, qualunque funzione potremmo vederla come il prodotto della stessa con il gradino unitario. Un esempio immediato è la \textbf{funzione rampa} $t1(t)$ di cui si riporta sopra la trasformata: nulla fino a $0$ da sinistra, poi lineare $y=t$. 

\section{Sistemi LTI nel dominio di Laplace}
\begin{prop}
Abbiamo visto che, per un sistema lineare (non necessariamente TI), è possibile scrivere traiettoria di stato ed uscita come una \textbf{somma di un'evoluzione libera ed una forzata} (vedi \eqref{sec:traj_somma_evoluz}). Anche nel dominio di Laplace questo è possibile. In particolare, vale:
\begin{equation}
X(s) = X_L(s) + X_F(s), \quad \quad Y(s) = Y_L(s) + Y_F(s)
\end{equation}
\end{prop}
\subsection{Equazioni delle trasformate delle traiettorie}
Se consideriamo un sistema LTI, è possibile \textbf{calcolare le equazioni esplicite della trasformata della traiettoria di stato e di uscita}, evidenziando le due evoluzioni che la compongono, analogamente a quanto fatto in \eqref{subsec:eq_traj_lti_scalare_gen}. Analizziamo direttamente il caso generale (i.e.  $x \in \R^n, y \in \R^p, u \in \R^m$): 

%\begin{defin}{}{}
\begin{equation*}
\begin{dcases}
\dot x(t) = Ax(t) + Bu(t) \\
y(t) = Cx(t) + Du(t)
\end{dcases}, \quad x(0) = x_0
\end{equation*}
Definiamo ora le \textbf{trasformate di Laplace} di stato, ingresso e uscita:
\begin{equation}
X(s) \coloneqq \lt{x(t)}, \quad \quad Y(s) \coloneqq \lt{y(t)}, \quad \quad U(s) \coloneqq \lt{u(t)}
\end{equation}
Trasformiamo entrambi i membri delle equazioni, sfruttando le proprietà di linearità e derivazione:
\begin{equation*}
\begin{dcases}
\lt{\dot x(t)} = sX(s) - x(0) = AX(s) + BU(s)\\
Y(s) = CX(s) + DU(s) 
\end{dcases} \rightarrow 
\begin{dcases}
sX(s) - AX(s) = x(0) + BU(s) \\
Y(s) = CX(s) + DU(s) 
\end{dcases} = (\star)
\end{equation*}
Raccogliamo al primo membro e moltiplichiamo $s$ per la matrice identica ($n \times n$) $I$, in modo da rendere matematicamente possibile una differenza di matrici\footnote{
Moltiplicare uno scalare $k$ per una matrice $M$ equivale a moltiplicare $k$ per l'identica $I$, e poi moltiplicare per $M$.}. Esplicitiamo poi $X(s)$ dalla prima equazione:

\begin{equation*}
(\star) \rightarrow
\begin{dcases}
(sI-A)X(s) = x_0 + BU(s) \\
Y(s) = CX(s) + DU(s) 
\end{dcases} \rightarrow \begin{dcases}
X(s) = (sI-A)^{-1}x_0 + (sI-A)^{-1}BU(s) \\
Y(s) = CX(s) + DU(s) 
\end{dcases}
\end{equation*}
Sostituendo l'espressione della $X(s)$ all'interno dell'equazione di uscita, si ha
\begin{center}
\boxed{
\begin{tabular}{ccccccc}
    $X(s)$ & $=$ & \parbox{2cm}{\centering
    $(sI-A)^{-1}$} &
  $x_0$ & $+$ & \parbox{3cm}{\centering
    $(sI-A)^{-1}B$} & $U(s)$ \\[0.13cm]
    $Y(s)$ & $=$ & \parbox{2cm}{\centering
    $C(sI-A)^{-1}$} &
  $x_0$ & $+$ & \parbox{3cm}{\centering
    $\sparen{C(sI-A)^{-1}B + D}$} & $U(s)$ \\
\end{tabular}
}
\end{center}
\newpage
In particolare, individuiamo:
\subsubsection{Trasformate dell'evoluzione libera}
\begin{equation}
X_L(s) = (sI-A)^{-1}x_0, \quad \quad \quad Y_L(s) = C(sI-A)^{-1}x_0
\end{equation}
\subsubsection{Trasformate dell'evoluzione forzata}
\begin{equation}
X_F(s) = (sI-A)^{-1} BU(s), \quad \quad \quad Y_F(s) = \sparen{C(sI-A)^{-1}B + D}U(s)
\end{equation}
%\end{defin}

\subsection{Funzione di trasferimento}

















